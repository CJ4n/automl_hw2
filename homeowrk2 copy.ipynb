{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from os import path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    RFECV,\n",
    "    SelectKBest,\n",
    "    VarianceThreshold,\n",
    "    f_classif,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from supervised.automl import AutoML\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_JOBS = -1\n",
    "TRAIN_TIME_LIMIT_AUTOGLUON = 60 * 1 * 1\n",
    "TRAIN_TIME_LIMIT_MLJAR = 60 * 1 * 1\n",
    "OUTPUT_DIR_MANUAL = path.join(\"output\", \"manual\")\n",
    "OUTPUT_DIR_AUTOGLUON = path.join(\"output\", \"autogluon\")\n",
    "OUTPUT_DIR_MLJAR = path.join(\"output\", \"mljar\")\n",
    "UNIQUE_ID = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "APPLY_REMOVE_LOW_VARIANCE_FEATURES = False\n",
    "APPLY_REMOVE_CORRELATED_FEATURES = False\n",
    "APPLY_REMOVE_RANDOM_FEATURES = False\n",
    "APPLY_RECURSEIVE_FEATURE_ELIMINATION = True\n",
    "APPLY_ANOVA = False\n",
    "ANOVE_FEATURES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the output directories exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output directory output\\manual\\20240115_213358\n",
      "Creating output directory output\\autogluon\\20240115_213358\n",
      "Creating output directory output\\mljar\\20240115_213358\n"
     ]
    }
   ],
   "source": [
    "for output_dir in [OUTPUT_DIR_MANUAL, OUTPUT_DIR_AUTOGLUON, OUTPUT_DIR_MLJAR]:\n",
    "    if not path.exists(path.join(output_dir, UNIQUE_ID)):\n",
    "        print(f\"Creating output directory {path.join(output_dir, UNIQUE_ID)}\")\n",
    "        os.makedirs(path.join(output_dir, UNIQUE_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(train_x, valid_x, test_x, threshold=0.95):\n",
    "    corr_matrix = np.corrcoef(train_x, rowvar=False)\n",
    "    upper = np.triu(corr_matrix, k=1)\n",
    "    to_drop = [i for i in range(upper.shape[1]) if any(upper[:, i] > threshold)]\n",
    "\n",
    "    train_x = np.delete(train_x, to_drop, axis=1)\n",
    "    valid_x = np.delete(valid_x, to_drop, axis=1)\n",
    "    test_x = np.delete(test_x, to_drop, axis=1)\n",
    "\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_variance_features(train_x, valid_x, test_x, threshold=(0.8 * (1 - 0.8))):\n",
    "    sel = VarianceThreshold(threshold=threshold)\n",
    "    sel.fit(train_x)\n",
    "    train_x = train_x[:, sel.get_support(indices=True)]\n",
    "    valid_x = valid_x[:, sel.get_support(indices=True)]\n",
    "    test_x = test_x[:, sel.get_support(indices=True)]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_features(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    importance=0.005,\n",
    "):\n",
    "    tree: DecisionTreeClassifier = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(train_x, train_y)\n",
    "    importances = tree.feature_importances_\n",
    "\n",
    "    important_indices = [i for i, imp in enumerate(importances) if imp > importance]\n",
    "    train_x = train_x[:, important_indices]\n",
    "    valid_x = valid_x[:, important_indices]\n",
    "    test_x = test_x[:, important_indices]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_filter(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    k: int = 50,\n",
    "):\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    selector.fit(train_x, train_y)\n",
    "\n",
    "    train_x = selector.transform(train_x)\n",
    "    valid_x = selector.transform(valid_x)\n",
    "    test_x = selector.transform(test_x)\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_proba(model, test_x, output_path_proba):\n",
    "    proba = model.predict_proba(test_x)\n",
    "\n",
    "    if isinstance(proba, pd.DataFrame):\n",
    "        proba = proba.values\n",
    "\n",
    "    np.savetxt(\n",
    "        output_path_proba,\n",
    "        proba[:, 1],\n",
    "        delimiter=\"\\n\",\n",
    "        header='\"313201_313212\"',\n",
    "        comments=\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_model(model, output_path_model):\n",
    "    joblib.dump(model, output_path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_feature_selection(train_x, train_y, valid_x, test_x):\n",
    "    estimator_et = ExtraTreesClassifier(random_state=0)\n",
    "    rfe_et = RFE(estimator=estimator_et, n_features_to_select=250)\n",
    "    rfe_et.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfe_et.support_]\n",
    "    valid_x = valid_x[:, rfe_et.support_]\n",
    "    test_x = test_x[:, rfe_et.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    estimator_rf = RandomForestClassifier(random_state=0)\n",
    "    rfe_rf = RFE(estimator=estimator_rf, n_features_to_select=125)\n",
    "    rfe_rf.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfe_rf.support_]\n",
    "    valid_x = valid_x[:, rfe_rf.support_]\n",
    "    test_x = test_x[:, rfe_rf.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    rfecv_et = RFECV(estimator=estimator_et, cv=3, min_features_to_select=25)\n",
    "    rfecv_et.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfecv_et.support_]\n",
    "    valid_x = valid_x[:, rfecv_et.support_]\n",
    "    test_x = test_x[:, rfecv_et.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    rfecv_rf = RFECV(estimator=estimator_rf, cv=3, min_features_to_select=15)\n",
    "    rfecv_rf.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfecv_rf.support_]\n",
    "    valid_x = valid_x[:, rfecv_rf.support_]\n",
    "    test_x = test_x[:, rfecv_rf.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    selected_columns = np.where(rfecv_rf.support_)[0]\n",
    "\n",
    "    os.makedirs(path.join(\"output\", UNIQUE_ID), exist_ok=True)\n",
    "\n",
    "    np.savetxt(\n",
    "        path.join(\"output\", UNIQUE_ID, \"selected_features.txt\"),\n",
    "        selected_columns,\n",
    "        fmt=\"%d\",\n",
    "    )\n",
    "\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "_test_x = pd.read_table(prefix + \"artificial_test.data\", sep=\" \", header=None)\n",
    "_test_x.drop(_test_x.columns[500], axis=1, inplace=True)\n",
    "_train_y = pd.read_table(prefix + \"artificial_train.labels\", header=None)\n",
    "_train_x = pd.read_table(prefix + \"artificial_train.data\", sep=\" \", header=None)\n",
    "_train_x.drop(_train_x.columns[500], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_x = np.array(_test_x, dtype=float, copy=True)\n",
    "_train_x = np.array(_train_x, dtype=float, copy=True)\n",
    "_train_y = np.array(_train_y, dtype=float, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_x, _train_y = shuffle(_train_x, _train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_validation_data():\n",
    "    split = 400\n",
    "    train_x, valid_x = _train_x[split:].copy(), _train_x[:split].copy()\n",
    "    train_y, valid_y = _train_y[split:].copy(), _train_y[:split].copy()\n",
    "    return train_x, train_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 500) (1600, 1) (400, 500) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, valid_x, valid_y = get_train_and_validation_data()\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 250) (400, 250) (600, 250)\n",
      "(1600, 125) (400, 125) (600, 125)\n",
      "(1600, 25) (400, 25) (600, 25)\n",
      "(1600, 20) (400, 20) (600, 20)\n",
      "(1600, 20) (400, 20) (600, 20)\n"
     ]
    }
   ],
   "source": [
    "if APPLY_RECURSEIVE_FEATURE_ELIMINATION:\n",
    "    train_x, valid_x, test_x = perform_feature_selection(\n",
    "        train_x, train_y.copy().ravel(), valid_x, _test_x\n",
    "    )\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_CORRELATED_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_highly_correlated_features(\n",
    "        train_x, valid_x, _test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_LOW_VARIANCE_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_low_variance_features(train_x, valid_x, test_x)\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_RANDOM_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_random_features(\n",
    "        train_x=train_x, train_y=train_y, valid_x=valid_x, test_x=test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_ANOVA:\n",
    "    train_x, valid_x, test_x = anova_filter(\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        test_x=test_x,\n",
    "        k=ANOVE_FEATURES,\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 20)\n",
      "train_y.shape:  (1600, 1)\n",
      "valid_x.shape:  (400, 20)\n",
      "valid_y.shape:  (400, 1)\n",
      "test_x.shape:  (600, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x.shape: \", train_x.shape)\n",
    "print(\"train_y.shape: \", train_y.shape)\n",
    "print(\"valid_x.shape: \", valid_x.shape)\n",
    "print(\"valid_y.shape: \", valid_y.shape)\n",
    "print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train manual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7775000\ttotal: 154ms\tremaining: 1m 17s\n",
      "100:\tlearn: 0.9162500\ttotal: 331ms\tremaining: 1.3s\n",
      "200:\tlearn: 0.9418750\ttotal: 571ms\tremaining: 850ms\n",
      "300:\tlearn: 0.9631250\ttotal: 831ms\tremaining: 549ms\n",
      "400:\tlearn: 0.9775000\ttotal: 1.08s\tremaining: 266ms\n",
      "499:\tlearn: 0.9862500\ttotal: 1.34s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;stacked_ensemble_1&#x27;,\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[(&#x27;mlp&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              (&#x27;mlpclassifier&#x27;,\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver=&#x27;lbfgs&#x27;,\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             (&#x27;rf&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;stacked_ensemble_1&#x27;,\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[(&#x27;mlp&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              (&#x27;mlpclassifier&#x27;,\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver=&#x27;lbfgs&#x27;,\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             (&#x27;rf&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>stacked_ensemble_1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>stacked_ensemble_2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=30, min_samples_leaf=2,\n",
       "                           min_samples_split=5, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=30, min_samples_leaf=2,\n",
       "                           min_samples_split=5, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>et</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                     random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000020E38ED5C70&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False,\n",
       "              eval_metric=&lt;function balanced_accuracy_score at 0x0000020E28461CA0&gt;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('stacked_ensemble_1',\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[('mlp',\n",
       "                                                              Pipeline(steps=[('standardscaler',\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              ('mlpclassifier',\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver='lbfgs',\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             ('rf',\n",
       "                                                              Pipeline(steps=[('standardscaler',\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_classifiers_1 = [\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"rf\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "base_classifiers_2 = [\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GradientBoostingClassifier(\n",
    "                random_state=SEED,\n",
    "                max_features=None,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=5,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "stacked_ensamble_1 = StackingClassifier(\n",
    "    estimators=base_classifiers_1, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "\n",
    "stacked_ensamble_2 = StackingClassifier(\n",
    "    estimators=base_classifiers_2, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "\n",
    "committee_models = [\n",
    "    (\"stacked_ensemble_1\", stacked_ensamble_1),\n",
    "    (\"stacked_ensemble_2\", stacked_ensamble_2),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GradientBoostingClassifier(\n",
    "                random_state=SEED,\n",
    "                max_features=None,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=5,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"et\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            ExtraTreesClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"rf\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"cb\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            CatBoostClassifier(\n",
    "                iterations=500,\n",
    "                learning_rate=0.03,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                border_count=32,\n",
    "                cat_features=None,\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"Accuracy\",\n",
    "                random_seed=SEED,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=100,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"xgb\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            XGBClassifier(\n",
    "                random_state=SEED,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric=balanced_accuracy_score,\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.02,\n",
    "                max_depth=6,\n",
    "                min_child_weight=1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                gamma=0,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=1.0,\n",
    "                scale_pos_weight=1,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "committee_model = VotingClassifier(committee_models, voting=\"soft\")\n",
    "committee_model.fit(train_x.copy(), train_y.copy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Balanced Accuracy: 0.8999774949363607\n"
     ]
    }
   ],
   "source": [
    "y_pred = committee_model.predict(valid_x)\n",
    "balanced_accuracy = balanced_accuracy_score(valid_y, y_pred)\n",
    "\n",
    "print(f\"Model Balanced Accuracy: {balanced_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_proba = path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model_proba.txt\")\n",
    "output_path_model = path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model.pkl\")\n",
    "dump_proba(committee_model, test_x, output_path_proba)\n",
    "dump_model(committee_model, output_path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with Autogloun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 21) (400, 21)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.concatenate((train_x.copy(), train_y.copy()), axis=1)\n",
    "train_data_pd = pd.DataFrame(train_data, copy=True)\n",
    "train_data_pd.rename(columns={train_data_pd.columns[-1]: \"class\"}, inplace=True)\n",
    "\n",
    "valid_data = np.concatenate((valid_x.copy(), valid_y.copy()), axis=1)\n",
    "valid_data_pd = pd.DataFrame(data=valid_data, copy=True)\n",
    "valid_data_pd.rename(columns={valid_data_pd.columns[-1]: \"class\"}, inplace=True)\n",
    "\n",
    "print(train_data_pd.shape, valid_data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"output\\autogluon\\20240115_213358\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 60 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: output\\autogluon\\20240115_213358/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 35 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 25 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 25s\n",
      "AutoGluon will save models to \"output\\autogluon\\20240115_213358\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.40 GB / 15.71 GB (40.7%)\n",
      "Disk Space Avail:   42.24 GB / 357.30 GB (11.8%)\n",
      "===================================================\n",
      "Train Data Rows:    1600\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1.0, class 0 = -1.0\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1.0) vs negative (-1.0) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6550.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 20 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 24.86s of the 24.86s of remaining time.\n",
      "\t0.8837\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 24.55s of the 24.54s of remaining time.\n",
      "\t0.885\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 24.41s of the 24.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.8938\t = Validation score   (balanced_accuracy)\n",
      "\t10.32s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 5.01s of the 5.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.885\t = Validation score   (balanced_accuracy)\n",
      "\t5.61s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 24.86s of the -8.0s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 0.386, 'LightGBMXT_BAG_L1': 0.341, 'KNeighborsUnif_BAG_L1': 0.273}\n",
      "\t0.8994\t = Validation score   (balanced_accuracy)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 33.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"output\\autogluon\\20240115_213358\")\n"
     ]
    }
   ],
   "source": [
    "save_path = path.join(OUTPUT_DIR_AUTOGLUON, UNIQUE_ID)\n",
    "predictor = TabularPredictor(\n",
    "    label=\"class\",\n",
    "    path=save_path,\n",
    "    eval_metric=\"balanced_accuracy\",\n",
    "    problem_type=\"binary\",\n",
    ").fit(\n",
    "    train_data=train_data_pd,\n",
    "    time_limit=TRAIN_TIME_LIMIT_AUTOGLUON,\n",
    "    presets=\"best_quality\",\n",
    "    hyperparameters=\"default\",\n",
    "    fit_weighted_ensemble=True,\n",
    "    fit_full_last_level_weighted_ensemble=True,\n",
    "    full_weighted_ensemble_additionally=True,\n",
    "    # num_bag_folds=15,\n",
    "    # num_bag_sets=25,\n",
    "    num_stack_levels=3,\n",
    "    auto_stack=True,\n",
    "    dynamic_stacking=True,\n",
    "    feature_generator=\"auto\",\n",
    "    # hyperparameter_tune_kwargs={\n",
    "    #     \"scheduler\": \"local\",\n",
    "    #     \"searcher\": \"auto\",\n",
    "    #     \"time_out\": 1200,\n",
    "    #     \"num_trials\": 30,\n",
    "    # },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.537136</td>\n",
       "      <td>10.784624</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.441244</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.893767</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.207636</td>\n",
       "      <td>10.322308</td>\n",
       "      <td>0.207636</td>\n",
       "      <td>10.322308</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.884989</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>5.606004</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>5.606004</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.884984</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.080110</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.080110</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.883744</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.246393</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>0.246393</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_val        eval_metric  pred_time_val  \\\n",
       "0    WeightedEnsemble_L2   0.899390  balanced_accuracy       0.537136   \n",
       "1      LightGBMXT_BAG_L1   0.893767  balanced_accuracy       0.207636   \n",
       "2        LightGBM_BAG_L1   0.884989  balanced_accuracy       0.063991   \n",
       "3  KNeighborsDist_BAG_L1   0.884984  balanced_accuracy       0.080110   \n",
       "4  KNeighborsUnif_BAG_L1   0.883744  balanced_accuracy       0.246393   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0  10.784624                0.002997           0.441244            2   \n",
       "1  10.322308                0.207636          10.322308            1   \n",
       "2   5.606004                0.063991           5.606004            1   \n",
       "3   0.009526                0.080110           0.009526            1   \n",
       "4   0.011545                0.246393           0.011545            1   \n",
       "\n",
       "   can_infer  fit_order  \n",
       "0       True          5  \n",
       "1       True          3  \n",
       "2       True          4  \n",
       "3       True          2  \n",
       "4       True          1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balanced_accuracy': 0.8948263359255832,\n",
       " 'accuracy': 0.895,\n",
       " 'mcc': 0.7900478835432104,\n",
       " 'roc_auc': 0.9474881848415894,\n",
       " 'f1': 0.8923076923076924,\n",
       " 'precision': 0.9015544041450777,\n",
       " 'recall': 0.883248730964467}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(valid_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_proba = path.join(\n",
    "    OUTPUT_DIR_AUTOGLUON, UNIQUE_ID, \"autogluon_model_proba.txt\"\n",
    ")\n",
    "dump_proba(predictor, pd.DataFrame(test_x), output_path_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with MLJAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...  1. -1. -1.]\n",
      "AutoML directory: output\\mljar\\20240115_213358\\tmp\n",
      "The task is binary_classification with evaluation metric f1\n",
      "AutoML will use algorithms: ['Decision Tree', 'Linear', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree f1 0.702703 trained in 2.97 seconds\n",
      "Disable stacking for split validation\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "2_DecisionTree f1 0.610778 trained in 2.98 seconds\n",
      "3_DecisionTree f1 0.610778 trained in 3.31 seconds\n",
      "4_Linear f1 0.614458 trained in 5.7 seconds\n",
      "Skip default_algorithms because of the time limit.\n",
      "* Step not_so_random will try to check up to 63 models\n",
      "14_LightGBM f1 0.860759 trained in 3.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_Xgboost f1 0.853503 trained in 4.59 seconds\n",
      "23_CatBoost f1 0.867925 trained in 3.21 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: feature_15_sum_feature_5\n",
      "Add Golden Feature: feature_14_multiply_feature_11\n",
      "Add Golden Feature: feature_19_multiply_feature_2\n",
      "Add Golden Feature: feature_8_diff_feature_16\n",
      "Add Golden Feature: feature_11_ratio_feature_18\n",
      "Add Golden Feature: feature_18_ratio_feature_11\n",
      "Add Golden Feature: feature_17_multiply_feature_3\n",
      "Add Golden Feature: feature_7_diff_feature_8\n",
      "Add Golden Feature: feature_19_sum_feature_17\n",
      "Add Golden Feature: feature_6_ratio_feature_2\n",
      "Created 10 Golden Features in 14.51 seconds.\n",
      "23_CatBoost_GoldenFeatures f1 0.851852 trained in 19.07 seconds\n",
      "Skip kmeans_features because of the time limit.\n",
      "Not enough time to perform features selection. Skip\n",
      "Time needed for features selection ~ 20.0 seconds\n",
      "Please increase total_time_limit to at least (255 seconds) to have features selection\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "24_CatBoost f1 0.869565 trained in 4.01 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble f1 0.876543 trained in 3.47 seconds\n",
      "AutoML fit time: 71.32 seconds\n",
      "AutoML best model: Ensemble\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoML(eval_metric=&#x27;f1&#x27;, ml_task=&#x27;binary_classification&#x27;, mode=&#x27;Compete&#x27;,\n",
       "       random_state=42, results_path=&#x27;output\\\\mljar\\\\20240115_213358\\\\tmp&#x27;,\n",
       "       total_time_limit=60)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML(eval_metric=&#x27;f1&#x27;, ml_task=&#x27;binary_classification&#x27;, mode=&#x27;Compete&#x27;,\n",
       "       random_state=42, results_path=&#x27;output\\\\mljar\\\\20240115_213358\\\\tmp&#x27;,\n",
       "       total_time_limit=60)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AutoML(eval_metric='f1', ml_task='binary_classification', mode='Compete',\n",
       "       random_state=42, results_path='output\\\\mljar\\\\20240115_213358\\\\tmp',\n",
       "       total_time_limit=60)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = AutoML(\n",
    "    mode=\"Compete\",\n",
    "    ml_task=\"binary_classification\",\n",
    "    total_time_limit=TRAIN_TIME_LIMIT_MLJAR,\n",
    "    eval_metric=\"f1\",\n",
    "    random_state=SEED,\n",
    "    results_path=path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID, \"tmp\"),\n",
    ")\n",
    "train_y = train_y.copy().reshape(-1)\n",
    "print(train_y)\n",
    "automl.fit(train_x.copy(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 22:08:55,986 supervised.exceptions ERROR Missing column: feature_2 in input data. Cannot predict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 20) (400, 1)\n",
      "(1600, 20) (1600,)\n"
     ]
    },
    {
     "ename": "AutoMLException",
     "evalue": "Missing column: feature_2 in input data. Cannot predict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAutoMLException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(valid_x\u001b[38;5;241m.\u001b[39mshape, valid_y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_x\u001b[38;5;241m.\u001b[39mshape, train_y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m score \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(valid_y, predictions)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Balanced Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\supervised\\automl.py:473\u001b[0m, in \u001b[0;36mAutoML.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m, X: Union[List, numpy\u001b[38;5;241m.\u001b[39mndarray, pandas\u001b[38;5;241m.\u001b[39mDataFrame]\n\u001b[0;32m    456\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03m    Computes class probabilities from AutoML best model.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m    This method can only be used for classification tasks.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    471\u001b[0m \n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\supervised\\base_automl.py:1540\u001b[0m, in \u001b[0;36mBaseAutoML._predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AutoMLException(\n\u001b[0;32m   1534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod `predict_proba()` can only be used when in classification tasks. Current task: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ml_task\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1535\u001b[0m     )\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# Make and return predictions\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;66;03m# If classification task the result is in column 'label'\u001b[39;00m\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;66;03m# Need to drop `label` column.\u001b[39;00m\n\u001b[1;32m-> 1540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[1;32mc:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\supervised\\base_automl.py:1468\u001b[0m, in \u001b[0;36mBaseAutoML._base_predict\u001b[1;34m(self, X, model)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m input_columns:\n\u001b[1;32m-> 1468\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AutoMLException(\n\u001b[0;32m   1469\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in input data. Cannot predict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1470\u001b[0m         )\n\u001b[0;32m   1472\u001b[0m X \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "\u001b[1;31mAutoMLException\u001b[0m: Missing column: feature_2 in input data. Cannot predict"
     ]
    }
   ],
   "source": [
    "print(valid_x.shape, valid_y.shape)\n",
    "print(train_x.shape, train_y.shape)\n",
    "predictions = automl.predict_proba(valid_y.copy())\n",
    "\n",
    "score = balanced_accuracy_score(valid_y, predictions)\n",
    "\n",
    "print(f\"Model Balanced Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID, \"mljar_model_proba.txt\")\n",
    "dump_proba(automl, test_x, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
