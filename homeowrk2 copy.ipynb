{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from os import path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    RFECV,\n",
    "    SelectKBest,\n",
    "    VarianceThreshold,\n",
    "    f_classif,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from supervised.automl import AutoML\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_JOBS = -1\n",
    "TRAIN_TIME_LIMIT_AUTOGLUON = 60 * 1 * 1\n",
    "TRAIN_TIME_LIMIT_MLJAR = 60 * 1 * 1\n",
    "OUTPUT_DIR_MANUAL = path.join(\"output\", \"manual\")\n",
    "OUTPUT_DIR_AUTOGLUON = path.join(\"output\", \"autogluon\")\n",
    "OUTPUT_DIR_MLJAR = path.join(\"output\", \"mljar\")\n",
    "UNIQUE_ID = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "APPLY_REMOVE_LOW_VARIANCE_FEATURES = False\n",
    "APPLY_REMOVE_CORRELATED_FEATURES = False\n",
    "APPLY_REMOVE_RANDOM_FEATURES = False\n",
    "APPLY_RECURSEIVE_FEATURE_ELIMINATION = True\n",
    "APPLY_ANOVA = False\n",
    "ANOVE_FEATURES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the output directories exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output directory output\\manual\\20240115_225836\n",
      "Creating output directory output\\autogluon\\20240115_225836\n",
      "Creating output directory output\\mljar\\20240115_225836\n"
     ]
    }
   ],
   "source": [
    "for output_dir in [OUTPUT_DIR_MANUAL, OUTPUT_DIR_AUTOGLUON, OUTPUT_DIR_MLJAR]:\n",
    "    if not path.exists(path.join(output_dir, UNIQUE_ID)):\n",
    "        print(f\"Creating output directory {path.join(output_dir, UNIQUE_ID)}\")\n",
    "        os.makedirs(path.join(output_dir, UNIQUE_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(train_x, valid_x, test_x, threshold=0.95):\n",
    "    corr_matrix = np.corrcoef(train_x, rowvar=False)\n",
    "    upper = np.triu(corr_matrix, k=1)\n",
    "    to_drop = [i for i in range(upper.shape[1]) if any(upper[:, i] > threshold)]\n",
    "\n",
    "    train_x = np.delete(train_x, to_drop, axis=1)\n",
    "    valid_x = np.delete(valid_x, to_drop, axis=1)\n",
    "    test_x = np.delete(test_x, to_drop, axis=1)\n",
    "\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_variance_features(train_x, valid_x, test_x, threshold=(0.8 * (1 - 0.8))):\n",
    "    sel = VarianceThreshold(threshold=threshold)\n",
    "    sel.fit(train_x)\n",
    "    train_x = train_x[:, sel.get_support(indices=True)]\n",
    "    valid_x = valid_x[:, sel.get_support(indices=True)]\n",
    "    test_x = test_x[:, sel.get_support(indices=True)]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_features(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    importance=0.005,\n",
    "):\n",
    "    tree: DecisionTreeClassifier = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(train_x, train_y)\n",
    "    importances = tree.feature_importances_\n",
    "\n",
    "    important_indices = [i for i, imp in enumerate(importances) if imp > importance]\n",
    "    train_x = train_x[:, important_indices]\n",
    "    valid_x = valid_x[:, important_indices]\n",
    "    test_x = test_x[:, important_indices]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_filter(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    k: int = 50,\n",
    "):\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    selector.fit(train_x, train_y)\n",
    "\n",
    "    train_x = selector.transform(train_x)\n",
    "    valid_x = selector.transform(valid_x)\n",
    "    test_x = selector.transform(test_x)\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_proba(model, test_x, output_path_proba):\n",
    "    proba = model.predict_proba(test_x)\n",
    "\n",
    "    if isinstance(proba, pd.DataFrame):\n",
    "        proba = proba.values\n",
    "\n",
    "    np.savetxt(\n",
    "        output_path_proba,\n",
    "        proba[:, 1],\n",
    "        delimiter=\"\\n\",\n",
    "        header='\"313201_313212\"',\n",
    "        comments=\"\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_model(model, output_path_model):\n",
    "    joblib.dump(model, output_path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_feature_selection(train_x, train_y, valid_x, test_x):\n",
    "    estimator_et = ExtraTreesClassifier(random_state=0)\n",
    "    rfe_et = RFE(estimator=estimator_et, n_features_to_select=250)\n",
    "    rfe_et.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfe_et.support_]\n",
    "    valid_x = valid_x[:, rfe_et.support_]\n",
    "    test_x = test_x[:, rfe_et.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    estimator_rf = RandomForestClassifier(random_state=0)\n",
    "    rfe_rf = RFE(estimator=estimator_rf, n_features_to_select=125)\n",
    "    rfe_rf.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfe_rf.support_]\n",
    "    valid_x = valid_x[:, rfe_rf.support_]\n",
    "    test_x = test_x[:, rfe_rf.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    rfecv_et = RFECV(estimator=estimator_et, cv=3, min_features_to_select=25)\n",
    "    rfecv_et.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfecv_et.support_]\n",
    "    valid_x = valid_x[:, rfecv_et.support_]\n",
    "    test_x = test_x[:, rfecv_et.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    rfecv_rf = RFECV(estimator=estimator_rf, cv=3, min_features_to_select=15)\n",
    "    rfecv_rf.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfecv_rf.support_]\n",
    "    valid_x = valid_x[:, rfecv_rf.support_]\n",
    "    test_x = test_x[:, rfecv_rf.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    selected_columns = np.where(rfecv_rf.support_)[0]\n",
    "\n",
    "    os.makedirs(path.join(\"output\", UNIQUE_ID), exist_ok=True)\n",
    "\n",
    "    np.savetxt(\n",
    "        path.join(\"output\", UNIQUE_ID, \"selected_features.txt\"),\n",
    "        selected_columns,\n",
    "        fmt=\"%d\",\n",
    "    )\n",
    "\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "_test_x = pd.read_table(prefix + \"artificial_test.data\", sep=\" \", header=None)\n",
    "_test_x.drop(_test_x.columns[500], axis=1, inplace=True)\n",
    "_train_y = pd.read_table(prefix + \"artificial_train.labels\", header=None)\n",
    "_train_x = pd.read_table(prefix + \"artificial_train.data\", sep=\" \", header=None)\n",
    "_train_x.drop(_train_x.columns[500], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_x = np.array(_test_x, dtype=float, copy=True)\n",
    "_train_x = np.array(_train_x, dtype=float, copy=True)\n",
    "_train_y = np.array(_train_y, dtype=float, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_x, _train_y = shuffle(_train_x, _train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_validation_data():\n",
    "    split = 400\n",
    "    train_x, valid_x = _train_x[split:].copy(), _train_x[:split].copy()\n",
    "    train_y, valid_y = _train_y[split:].copy(), _train_y[:split].copy()\n",
    "    return train_x, train_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 500) (1600, 1) (400, 500) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, valid_x, valid_y = get_train_and_validation_data()\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 250) (400, 250) (600, 250)\n",
      "(1600, 125) (400, 125) (600, 125)\n",
      "(1600, 25) (400, 25) (600, 25)\n",
      "(1600, 20) (400, 20) (600, 20)\n",
      "(1600, 20) (400, 20) (600, 20)\n"
     ]
    }
   ],
   "source": [
    "if APPLY_RECURSEIVE_FEATURE_ELIMINATION:\n",
    "    train_x, valid_x, test_x = perform_feature_selection(\n",
    "        train_x, train_y.copy().ravel(), valid_x, _test_x\n",
    "    )\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_CORRELATED_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_highly_correlated_features(\n",
    "        train_x, valid_x, _test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_LOW_VARIANCE_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_low_variance_features(train_x, valid_x, test_x)\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_RANDOM_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_random_features(\n",
    "        train_x=train_x, train_y=train_y, valid_x=valid_x, test_x=test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_ANOVA:\n",
    "    train_x, valid_x, test_x = anova_filter(\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        test_x=test_x,\n",
    "        k=ANOVE_FEATURES,\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 20)\n",
      "train_y.shape:  (1600, 1)\n",
      "valid_x.shape:  (400, 20)\n",
      "valid_y.shape:  (400, 1)\n",
      "test_x.shape:  (600, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x.shape: \", train_x.shape)\n",
    "print(\"train_y.shape: \", train_y.shape)\n",
    "print(\"valid_x.shape: \", valid_x.shape)\n",
    "print(\"valid_y.shape: \", valid_y.shape)\n",
    "print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train manual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7775000\ttotal: 141ms\tremaining: 1m 10s\n",
      "100:\tlearn: 0.9162500\ttotal: 336ms\tremaining: 1.33s\n",
      "200:\tlearn: 0.9418750\ttotal: 582ms\tremaining: 866ms\n",
      "300:\tlearn: 0.9631250\ttotal: 837ms\tremaining: 553ms\n",
      "400:\tlearn: 0.9775000\ttotal: 1.11s\tremaining: 274ms\n",
      "499:\tlearn: 0.9862500\ttotal: 1.37s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;stacked_ensemble_1&#x27;,\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[(&#x27;mlp&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              (&#x27;mlpclassifier&#x27;,\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver=&#x27;lbfgs&#x27;,\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             (&#x27;rf&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;stacked_ensemble_1&#x27;,\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[(&#x27;mlp&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              (&#x27;mlpclassifier&#x27;,\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver=&#x27;lbfgs&#x27;,\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             (&#x27;rf&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>stacked_ensemble_1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>stacked_ensemble_2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=30, min_samples_leaf=2,\n",
       "                           min_samples_split=5, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=30, min_samples_leaf=2,\n",
       "                           min_samples_split=5, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>et</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                     random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x000001E1DF59DDC0&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False,\n",
       "              eval_metric=&lt;function balanced_accuracy_score at 0x000001E1CFAA8CA0&gt;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('stacked_ensemble_1',\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[('mlp',\n",
       "                                                              Pipeline(steps=[('standardscaler',\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              ('mlpclassifier',\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver='lbfgs',\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             ('rf',\n",
       "                                                              Pipeline(steps=[('standardscaler',\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_classifiers_1 = [\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"rf\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "base_classifiers_2 = [\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GradientBoostingClassifier(\n",
    "                random_state=SEED,\n",
    "                max_features=None,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=5,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "stacked_ensamble_1 = StackingClassifier(\n",
    "    estimators=base_classifiers_1, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "\n",
    "stacked_ensamble_2 = StackingClassifier(\n",
    "    estimators=base_classifiers_2, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "\n",
    "committee_models = [\n",
    "    (\"stacked_ensemble_1\", stacked_ensamble_1),\n",
    "    (\"stacked_ensemble_2\", stacked_ensamble_2),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GradientBoostingClassifier(\n",
    "                random_state=SEED,\n",
    "                max_features=None,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=5,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"et\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            ExtraTreesClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"rf\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"cb\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            CatBoostClassifier(\n",
    "                iterations=500,\n",
    "                learning_rate=0.03,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                border_count=32,\n",
    "                cat_features=None,\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"Accuracy\",\n",
    "                random_seed=SEED,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=100,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"xgb\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            XGBClassifier(\n",
    "                random_state=SEED,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric=balanced_accuracy_score,\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.02,\n",
    "                max_depth=6,\n",
    "                min_child_weight=1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                gamma=0,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=1.0,\n",
    "                scale_pos_weight=1,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "committee_model = VotingClassifier(committee_models, voting=\"soft\")\n",
    "committee_model.fit(train_x.copy(), train_y.copy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committee Model Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = committee_model.predict(train_x)\n",
    "balanced_accuracy = balanced_accuracy_score(train_y, y_pred)\n",
    "print(\"Committee Model Score:\", balanced_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Balanced Accuracy: 0.8999774949363607\n"
     ]
    }
   ],
   "source": [
    "y_pred = committee_model.predict(valid_x)\n",
    "balanced_accuracy = balanced_accuracy_score(valid_y, y_pred)\n",
    "\n",
    "print(f\"Model Balanced Accuracy: {balanced_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_proba = path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model_proba.txt\")\n",
    "output_path_model = path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model.pkl\")\n",
    "dump_proba(committee_model, test_x, output_path_proba)\n",
    "dump_model(committee_model, output_path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with Autogloun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((train_x.copy(), train_y.copy()), axis=1)\n",
    "train_data_pd = pd.DataFrame(train_data, copy=True)\n",
    "train_data_pd.rename(columns={train_data_pd.columns[-1]: \"class\"}, inplace=True)\n",
    "\n",
    "valid_data = np.concatenate((valid_x.copy(), valid_y.copy()), axis=1)\n",
    "valid_data_pd = pd.DataFrame(data=valid_data, copy=True)\n",
    "valid_data_pd.rename(columns={valid_data_pd.columns[-1]: \"class\"}, inplace=True)\n",
    "\n",
    "print(train_data_pd.shape, valid_data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = path.join(OUTPUT_DIR_AUTOGLUON, UNIQUE_ID)\n",
    "predictor = TabularPredictor(\n",
    "    label=\"class\",\n",
    "    path=save_path,\n",
    "    eval_metric=\"balanced_accuracy\",\n",
    "    problem_type=\"binary\",\n",
    ").fit(\n",
    "    train_data=train_data_pd,\n",
    "    time_limit=TRAIN_TIME_LIMIT_AUTOGLUON,\n",
    "    presets=\"best_quality\",\n",
    "    hyperparameters=\"default\",\n",
    "    fit_weighted_ensemble=True,\n",
    "    fit_full_last_level_weighted_ensemble=True,\n",
    "    full_weighted_ensemble_additionally=True,\n",
    "    # num_bag_folds=15,\n",
    "    # num_bag_sets=25,\n",
    "    num_stack_levels=3,\n",
    "    auto_stack=True,\n",
    "    dynamic_stacking=True,\n",
    "    feature_generator=\"auto\",\n",
    "    # hyperparameter_tune_kwargs={\n",
    "    #     \"scheduler\": \"local\",\n",
    "    #     \"searcher\": \"auto\",\n",
    "    #     \"time_out\": 1200,\n",
    "    #     \"num_trials\": 30,\n",
    "    # },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(valid_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_proba = path.join(\n",
    "    OUTPUT_DIR_AUTOGLUON, UNIQUE_ID, \"autogluon_model_proba.txt\"\n",
    ")\n",
    "dump_proba(predictor, pd.DataFrame(test_x), output_path_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with MLJAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML(\n",
    "    mode=\"Compete\",\n",
    "    ml_task=\"binary_classification\",\n",
    "    total_time_limit=TRAIN_TIME_LIMIT_MLJAR,\n",
    "    eval_metric=\"f1\",\n",
    "    random_state=SEED,\n",
    "    results_path=path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID, \"tmp\"),\n",
    ")\n",
    "train_y = train_y.copy().reshape(-1)\n",
    "print(train_y)\n",
    "automl.fit(train_x.copy(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_x.shape, valid_y.shape)\n",
    "print(train_x.shape, train_y.shape)\n",
    "predictions = automl.predict_proba(valid_y.copy())\n",
    "\n",
    "score = balanced_accuracy_score(valid_y, predictions)\n",
    "\n",
    "print(f\"Model Balanced Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID, \"mljar_model_proba.txt\")\n",
    "dump_proba(automl, test_x, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
