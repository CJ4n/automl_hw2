{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "####################################################################\n",
    "#                          Read data                               #\n",
    "####################################################################\n",
    "\n",
    "prefix = \"\"\n",
    "\n",
    "_test_x = pd.read_table(prefix + \"artificial_test.data\", sep=\" \", header=None)\n",
    "_test_x.drop(_test_x.columns[500], axis=1, inplace=True)\n",
    "_train_y = pd.read_table(prefix + \"artificial_train.labels\", header=None)\n",
    "_train_x = pd.read_table(prefix + \"artificial_train.data\", sep=\" \", header=None)\n",
    "_train_x.drop(_train_x.columns[500], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_validation_data():\n",
    "    split = 400\n",
    "    train_x, valid_x = _train_x[split:], _train_x[:split]\n",
    "    train_y, valid_y = _train_y[split:], _train_y[:split]\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"train_y.shape: \", train_y.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"valid_y.shape: \", valid_y.shape)\n",
    "    return train_x, train_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 500)\n",
      "train_y.shape:  (1600, 1)\n",
      "valid_x.shape:  (400, 500)\n",
      "valid_y.shape:  (400, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, valid_x, valid_y = get_train_and_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove Highly Correlated Columns\n",
    "def remove_highly_correlated_features(train_x, valid_x, threshold=0.95):\n",
    "    corr_matrix = train_x.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Find index of feature columns with correlation greater than threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    train_x = train_x.drop(to_drop, axis=1)\n",
    "    valid_x = valid_x.drop(to_drop, axis=1)\n",
    "    return train_x, valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x = remove_highly_correlated_features(train_x, valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 490)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove Low Variance Columns\n",
    "def remove_low_variance_features(train_x, valid_x, threshold=(0.8 * (1 - 0.8))):\n",
    "    sel = VarianceThreshold(threshold=threshold)\n",
    "    sel.fit(train_x)\n",
    "    train_x = train_x[train_x.columns[sel.get_support(indices=True)]]\n",
    "    valid_x = valid_x[valid_x.columns[sel.get_support(indices=True)]]\n",
    "    return train_x, valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x = remove_low_variance_features(train_x, valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 490)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove Random Columns (Optional)\n",
    "# This step is an approximation and should be tailored to your specific needs\n",
    "# Here we use a Decision Tree to estimate feature importance\n",
    "def remove_random_features(\n",
    "    train_x: pd.DataFrame,\n",
    "    train_y: pd.DataFrame,\n",
    "    valid_x: pd.DataFrame,\n",
    "    importance=0.005,\n",
    "):\n",
    "    tree: DecisionTreeClassifier = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(train_x, train_y)\n",
    "    importances = tree.feature_importances_\n",
    "\n",
    "    # Assume columns with very low importance are \"random\"\n",
    "    # This threshold can be adjusted based on domain knowledge\n",
    "    important_indices = [i for i, imp in enumerate(importances) if imp > importance]\n",
    "    train_x = train_x.iloc[:, important_indices]\n",
    "    valid_x = valid_x.iloc[:, important_indices]\n",
    "    return train_x, valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x = remove_random_features(\n",
    "    train_x=train_x, train_y=train_y, valid_x=valid_x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 54)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "def anove_filter(\n",
    "    train_x: pd.DataFrame,\n",
    "    train_y: pd.DataFrame,\n",
    "    valid_x: pd.DataFrame,\n",
    "    k: int = 50,\n",
    "):\n",
    "    # Using ANOVA F-test to select features\n",
    "    selector = SelectKBest(\n",
    "        f_classif, k=k\n",
    "    )  # Change k to select the number of features you want\n",
    "    selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get F-values and p-values for each feature\n",
    "    f_values = selector.scores_\n",
    "    p_values = selector.pvalues_\n",
    "\n",
    "    # Selecting features (you can use a threshold or select top k features)\n",
    "    selected_features = train_x.columns[selector.get_support()]\n",
    "\n",
    "    # Transforming train_x to include only the selected features\n",
    "    train_x = selector.transform(train_x)\n",
    "    valid_x = selector.transform(valid_x)\n",
    "    return train_x, valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x, valid_x = anove_filter(train_x=train_x, train_y=train_y, valid_x=valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"class\"\n",
    "train_y = train_y.rename(columns={0: label})\n",
    "valid_y = valid_y.rename(columns={0: label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_x, train_y[label]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 500)\n",
      "train_y.shape:  (1600, 1)\n",
      "valid_x.shape:  (400, 500)\n",
      "valid_y.shape:  (400, 1)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "(\n",
    "    original_train_x,\n",
    "    original_train_y,\n",
    "    original_valid_x,\n",
    "    original_valid_y,\n",
    ") = get_train_and_validation_data()\n",
    "for y, original_y in zip([train_y, valid_y], [original_train_y, original_valid_y]):\n",
    "    assert y.shape == original_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"some_path\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 1200 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: some_path/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 208 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 992 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 992s\n",
      "AutoGluon will save models to \"some_path\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.04 GB / 15.71 GB (38.4%)\n",
      "Disk Space Avail:   85.67 GB / 357.30 GB (24.0%)\n",
      "===================================================\n",
      "Train Data Rows:    1600\n",
      "Train Data Columns: 54\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6183.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.66 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 54 | ['0', '3', '10', '16', '28', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 54 | ['0', '3', '10', '16', '28', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t54 features in original data used to generate 54 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.66 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 991.9s of the 991.9s of remaining time.\n",
      "\t0.7532\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 991.83s of the 991.83s of remaining time.\n",
      "\t0.7532\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 991.77s of the 991.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.7753\t = Validation score   (balanced_accuracy)\n",
      "\t4.13s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 982.45s of the 982.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8299\t = Validation score   (balanced_accuracy)\n",
      "\t4.25s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 973.44s of the 973.43s of remaining time.\n",
      "\t0.7542\t = Validation score   (balanced_accuracy)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 971.93s of the 971.93s of remaining time.\n",
      "\t0.751\t = Validation score   (balanced_accuracy)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 970.56s of the 970.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
      "\t0.8492\t = Validation score   (balanced_accuracy)\n",
      "\t25.83s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 939.96s of the 939.96s of remaining time.\n",
      "\t0.6964\t = Validation score   (balanced_accuracy)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 939.11s of the 939.11s of remaining time.\n",
      "\t0.6986\t = Validation score   (balanced_accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 938.28s of the 938.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.6155\t = Validation score   (balanced_accuracy)\n",
      "\t9.3s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 923.98s of the 923.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
      "\t0.8418\t = Validation score   (balanced_accuracy)\n",
      "\t6.37s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 912.46s of the 912.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.6611\t = Validation score   (balanced_accuracy)\n",
      "\t9.64s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 897.83s of the 897.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
      "\t0.8375\t = Validation score   (balanced_accuracy)\n",
      "\t10.81s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 881.52s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.8492\t = Validation score   (balanced_accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 111.36s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"some_path\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "save_path = \"some_path\"\n",
    "# train for 3 minutes with increased num_boost_round\n",
    "predictor = TabularPredictor(\n",
    "    label=label, path=save_path, eval_metric=\"balanced_accuracy\",  problem_type=\"binary\"\n",
    ").fit(train_data, time_limit=60 * 20,presets = \"best_quality\", hyperparameters =\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.849250</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.023005</td>\n",
       "      <td>25.830919</td>\n",
       "      <td>0.023005</td>\n",
       "      <td>25.830919</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.849250</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.026011</td>\n",
       "      <td>26.691000</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.860081</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.841764</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.049008</td>\n",
       "      <td>6.374003</td>\n",
       "      <td>0.049008</td>\n",
       "      <td>6.374003</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.837537</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.047004</td>\n",
       "      <td>10.807577</td>\n",
       "      <td>0.047004</td>\n",
       "      <td>10.807577</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.829880</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.037004</td>\n",
       "      <td>4.248002</td>\n",
       "      <td>0.037004</td>\n",
       "      <td>4.248002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.035962</td>\n",
       "      <td>4.128309</td>\n",
       "      <td>0.035962</td>\n",
       "      <td>4.128309</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.754196</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.127038</td>\n",
       "      <td>1.319147</td>\n",
       "      <td>0.127038</td>\n",
       "      <td>1.319147</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.753204</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.753204</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.034993</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.034993</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.751047</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.122036</td>\n",
       "      <td>1.201920</td>\n",
       "      <td>0.122036</td>\n",
       "      <td>1.201920</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.698570</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.114997</td>\n",
       "      <td>0.661725</td>\n",
       "      <td>0.114997</td>\n",
       "      <td>0.661725</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.696421</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.110999</td>\n",
       "      <td>0.681231</td>\n",
       "      <td>0.110999</td>\n",
       "      <td>0.681231</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.661127</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.085006</td>\n",
       "      <td>9.637846</td>\n",
       "      <td>0.085006</td>\n",
       "      <td>9.637846</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.615534</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.092021</td>\n",
       "      <td>9.303558</td>\n",
       "      <td>0.092021</td>\n",
       "      <td>9.303558</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val        eval_metric  pred_time_val  \\\n",
       "0           CatBoost_BAG_L1   0.849250  balanced_accuracy       0.023005   \n",
       "1       WeightedEnsemble_L2   0.849250  balanced_accuracy       0.026011   \n",
       "2            XGBoost_BAG_L1   0.841764  balanced_accuracy       0.049008   \n",
       "3      LightGBMLarge_BAG_L1   0.837537  balanced_accuracy       0.047004   \n",
       "4           LightGBM_BAG_L1   0.829880  balanced_accuracy       0.037004   \n",
       "5         LightGBMXT_BAG_L1   0.775309  balanced_accuracy       0.035962   \n",
       "6   RandomForestGini_BAG_L1   0.754196  balanced_accuracy       0.127038   \n",
       "7     KNeighborsDist_BAG_L1   0.753204  balanced_accuracy       0.031000   \n",
       "8     KNeighborsUnif_BAG_L1   0.753204  balanced_accuracy       0.034993   \n",
       "9   RandomForestEntr_BAG_L1   0.751047  balanced_accuracy       0.122036   \n",
       "10    ExtraTreesEntr_BAG_L1   0.698570  balanced_accuracy       0.114997   \n",
       "11    ExtraTreesGini_BAG_L1   0.696421  balanced_accuracy       0.110999   \n",
       "12    NeuralNetTorch_BAG_L1   0.661127  balanced_accuracy       0.085006   \n",
       "13   NeuralNetFastAI_BAG_L1   0.615534  balanced_accuracy       0.092021   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   25.830919                0.023005          25.830919            1   \n",
       "1   26.691000                0.003006           0.860081            2   \n",
       "2    6.374003                0.049008           6.374003            1   \n",
       "3   10.807577                0.047004          10.807577            1   \n",
       "4    4.248002                0.037004           4.248002            1   \n",
       "5    4.128309                0.035962           4.128309            1   \n",
       "6    1.319147                0.127038           1.319147            1   \n",
       "7    0.007998                0.031000           0.007998            1   \n",
       "8    0.008001                0.034993           0.008001            1   \n",
       "9    1.201920                0.122036           1.201920            1   \n",
       "10   0.661725                0.114997           0.661725            1   \n",
       "11   0.681231                0.110999           0.681231            1   \n",
       "12   9.637846                0.085006           9.637846            1   \n",
       "13   9.303558                0.092021           9.303558            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True          7  \n",
       "1        True         14  \n",
       "2        True         11  \n",
       "3        True         13  \n",
       "4        True          4  \n",
       "5        True          3  \n",
       "6        True          5  \n",
       "7        True          2  \n",
       "8        True          1  \n",
       "9        True          6  \n",
       "10       True          9  \n",
       "11       True          8  \n",
       "12       True         12  \n",
       "13       True         10  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 54)\n",
      "(400, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'balanced_accuracy': 0.8362155388471177,\n",
       " 'accuracy': 0.8375,\n",
       " 'mcc': 0.6740293579627241,\n",
       " 'roc_auc': 0.9091478696741856,\n",
       " 'f1': 0.8257372654155496,\n",
       " 'precision': 0.8415300546448088,\n",
       " 'recall': 0.8105263157894737}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on validation data\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)\n",
    "valid_data = pd.concat([valid_x, valid_y[label]], axis=1)\n",
    "predictor.evaluate(valid_data)\n",
    "# best model WeightedEnsamble_L2 score 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
