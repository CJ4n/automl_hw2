{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "####################################################################\n",
    "#                          Read data                               #\n",
    "####################################################################\n",
    "\n",
    "prefix = \"\"\n",
    "\n",
    "_test_x = pd.read_table(prefix + \"artificial_test.data\", sep=\" \", header=None)\n",
    "_test_x.drop(_test_x.columns[500], axis=1, inplace=True)\n",
    "_train_y = pd.read_table(prefix + \"artificial_train.labels\", header=None)\n",
    "_train_x = pd.read_table(prefix + \"artificial_train.data\", sep=\" \", header=None)\n",
    "_train_x.drop(_train_x.columns[500], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    return _train_x.copy(), _train_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove Highly Correlated Columns\n",
    "corr_matrix = train_x.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "train_x = train_x.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 490)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove Low Variance Columns\n",
    "sel = VarianceThreshold(threshold=(0.8 * (1 - 0.8)))  # Example threshold\n",
    "train_x = sel.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 490)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove Random Columns (Optional)\n",
    "# This step is an approximation and should be tailored to your specific needs\n",
    "# Here we use a Decision Tree to estimate feature importance\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(train_x, train_y)\n",
    "importances = tree.feature_importances_\n",
    "\n",
    "# Assume columns with very low importance are \"random\"\n",
    "# This threshold can be adjusted based on domain knowledge\n",
    "important_indices = [i for i, imp in enumerate(importances) if imp > 0.01]\n",
    "train_x = train_x[:, important_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Using ANOVA F-test to select features\n",
    "selector = SelectKBest(f_classif, k=50)  # Change k to select the number of features you want\n",
    "selector.fit(train_x, train_y)\n",
    "\n",
    "# Get F-values and p-values for each feature\n",
    "f_values = selector.scores_\n",
    "p_values = selector.pvalues_\n",
    "\n",
    "# Selecting features (you can use a threshold or select top k features)\n",
    "selected_features = train_x.columns[selector.get_support()]\n",
    "\n",
    "# Transforming train_x to include only the selected features\n",
    "train_x_selected = selector.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_selected.shape\n",
    "train_x = train_x_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"class\"\n",
    "train_y.columns = [label]\n",
    "train_x = pd.DataFrame(train_x)\n",
    "\n",
    "# train_y = pd.DataFrame(train_y, columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_x, train_y[label]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"some_path\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"some_path\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.02 GB / 15.71 GB (38.3%)\n",
      "Disk Space Avail:   86.47 GB / 357.30 GB (24.2%)\n",
      "===================================================\n",
      "Train Data Rows:    2000\n",
      "Train Data Columns: 12\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [-1, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6144.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 12 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 12 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1600, Val Rows: 400\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8275\t = Validation score   (balanced_accuracy)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.8275\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.399732\tvalid_set's balanced_accuracy: 0.8575\n",
      "[2000]\tvalid_set's binary_logloss: 0.464121\tvalid_set's balanced_accuracy: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.87\t = Validation score   (balanced_accuracy)\n",
      "\t3.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8675\t = Validation score   (balanced_accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.855\t = Validation score   (balanced_accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8525\t = Validation score   (balanced_accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8725\t = Validation score   (balanced_accuracy)\n",
      "\t4.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8475\t = Validation score   (balanced_accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.855\t = Validation score   (balanced_accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "\t0.8375\t = Validation score   (balanced_accuracy)\n",
      "\t2.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.875\t = Validation score   (balanced_accuracy)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8575\t = Validation score   (balanced_accuracy)\n",
      "\t4.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.87\t = Validation score   (balanced_accuracy)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 0.273, 'XGBoost': 0.273, 'RandomForestGini': 0.182, 'RandomForestEntr': 0.182, 'NeuralNetTorch': 0.091}\n",
      "\t0.89\t = Validation score   (balanced_accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 24.05s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"some_path\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "save_path = \"some_path\"\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=label, path=save_path, eval_metric=\"balanced_accuracy\"\n",
    ").fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.251109</td>\n",
       "      <td>8.697992</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.531049</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.208777</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>1.208777</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>4.109244</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>4.109244</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>1.721323</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>1.721323</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.015993</td>\n",
       "      <td>3.027059</td>\n",
       "      <td>0.015993</td>\n",
       "      <td>3.027059</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.752002</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.752002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>4.864398</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>4.864398</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.636105</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.636105</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.079995</td>\n",
       "      <td>0.740787</td>\n",
       "      <td>0.079995</td>\n",
       "      <td>0.740787</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.080849</td>\n",
       "      <td>0.716876</td>\n",
       "      <td>0.080849</td>\n",
       "      <td>0.716876</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>0.739580</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>0.739580</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>2.340791</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>2.340791</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.033318</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.033318</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>1.618472</td>\n",
       "      <td>0.038901</td>\n",
       "      <td>1.618472</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val        eval_metric  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2     0.8900  balanced_accuracy       0.251109   \n",
       "1               XGBoost     0.8750  balanced_accuracy       0.007000   \n",
       "2              CatBoost     0.8725  balanced_accuracy       0.004002   \n",
       "3         LightGBMLarge     0.8700  balanced_accuracy       0.005997   \n",
       "4            LightGBMXT     0.8700  balanced_accuracy       0.015993   \n",
       "5              LightGBM     0.8675  balanced_accuracy       0.005996   \n",
       "6        NeuralNetTorch     0.8575  balanced_accuracy       0.004000   \n",
       "7        ExtraTreesEntr     0.8550  balanced_accuracy       0.078253   \n",
       "8      RandomForestGini     0.8550  balanced_accuracy       0.079995   \n",
       "9      RandomForestEntr     0.8525  balanced_accuracy       0.080849   \n",
       "10       ExtraTreesGini     0.8475  balanced_accuracy       0.077746   \n",
       "11      NeuralNetFastAI     0.8375  balanced_accuracy       0.010995   \n",
       "12       KNeighborsDist     0.8275  balanced_accuracy       0.033318   \n",
       "13       KNeighborsUnif     0.8275  balanced_accuracy       0.038901   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   8.697992                0.001011           0.531049            2   \n",
       "1   1.208777                0.007000           1.208777            1   \n",
       "2   4.109244                0.004002           4.109244            1   \n",
       "3   1.721323                0.005997           1.721323            1   \n",
       "4   3.027059                0.015993           3.027059            1   \n",
       "5   0.752002                0.005996           0.752002            1   \n",
       "6   4.864398                0.004000           4.864398            1   \n",
       "7   0.636105                0.078253           0.636105            1   \n",
       "8   0.740787                0.079995           0.740787            1   \n",
       "9   0.716876                0.080849           0.716876            1   \n",
       "10  0.739580                0.077746           0.739580            1   \n",
       "11  2.340791                0.010995           2.340791            1   \n",
       "12  0.009000                0.033318           0.009000            1   \n",
       "13  1.618472                0.038901           1.618472            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         14  \n",
       "1        True         11  \n",
       "2        True          7  \n",
       "3        True         13  \n",
       "4        True          3  \n",
       "5        True          4  \n",
       "6        True         12  \n",
       "7        True          9  \n",
       "8        True          5  \n",
       "9        True          6  \n",
       "10       True          8  \n",
       "11       True         10  \n",
       "12       True          2  \n",
       "13       True          1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()\n",
    "# best model WeightedEnsamble_L2 score 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
