{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mljar-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from os import path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    RFECV,\n",
    "    SelectKBest,\n",
    "    VarianceThreshold,\n",
    "    f_classif,\n",
    ")\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, mutual_info_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from supervised.automl import AutoML\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# from supervised.automl import AutoML  # mljar-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "SEED = 42\n",
    "N_JOBS = -1\n",
    "RANDOM_SEARCH_N_ITER = 1\n",
    "TRAIN_TIME_LIMIT_AUTOGLUON = 60 * 60 * 6\n",
    "TRAIN_TIME_LIMIT_MLJAR = 60 * 60 * 6\n",
    "OUTPUT_DIR_MANUAL = path.join(\"output\", \"manual\")\n",
    "OUTPUT_DIR_AUTOGLUON = path.join(\"output\", \"autogluon\")\n",
    "OUTPUT_DIR_MLJAR = path.join(\"output\", \"mljar\")\n",
    "UNIQUE_ID = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "APPLY_REMOVE_LOW_VARIANCE_FEATURES = False\n",
    "APPLY_REMOVE_CORRELATED_FEATURES = False\n",
    "APPLY_REMOVE_RANDOM_FEATURES = False\n",
    "APPLY_ANOVA = False\n",
    "ANOVE_FEATURES = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output directory output\\manual\\20240114_145731\n",
      "Creating output directory output\\autogluon\\20240114_145731\n",
      "Creating output directory output\\mljar\\20240114_145731\n"
     ]
    }
   ],
   "source": [
    "# prepare output directories\n",
    "for output_dir in [OUTPUT_DIR_MANUAL, OUTPUT_DIR_AUTOGLUON, OUTPUT_DIR_MLJAR]:\n",
    "    if not path.exists(path.join(output_dir, UNIQUE_ID)):\n",
    "        print(f\"Creating output directory {path.join(output_dir, UNIQUE_ID)}\")\n",
    "        os.makedirs(path.join(output_dir, UNIQUE_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(train_x, valid_x, test_x, threshold=0.95):\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = np.corrcoef(train_x, rowvar=False)\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = np.triu(corr_matrix, k=1)\n",
    "    # Find indices of feature columns with correlation greater than threshold\n",
    "    to_drop = [i for i in range(upper.shape[1]) if any(upper[:, i] > threshold)]\n",
    "\n",
    "    # Drop features from train, validation, and test set\n",
    "    train_x = np.delete(train_x, to_drop, axis=1)\n",
    "    valid_x = np.delete(valid_x, to_drop, axis=1)\n",
    "    test_x = np.delete(test_x, to_drop, axis=1)\n",
    "\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Low Variance Columns\n",
    "def remove_low_variance_features(train_x, valid_x, test_x, threshold=(0.8 * (1 - 0.8))):\n",
    "    sel = VarianceThreshold(threshold=threshold)\n",
    "    sel.fit(train_x)\n",
    "    train_x = train_x[:, sel.get_support(indices=True)]\n",
    "    valid_x = valid_x[:, sel.get_support(indices=True)]\n",
    "    test_x = test_x[:, sel.get_support(indices=True)]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Random Columns\n",
    "def remove_random_features(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    importance=0.005,\n",
    "):\n",
    "    tree: DecisionTreeClassifier = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(train_x, train_y)\n",
    "    importances = tree.feature_importances_\n",
    "\n",
    "    # Assume columns with very low importance are \"random\"\n",
    "    # This threshold can be adjusted based on domain knowledge\n",
    "    important_indices = [i for i, imp in enumerate(importances) if imp > importance]\n",
    "    train_x = train_x[:, important_indices]\n",
    "    valid_x = valid_x[:, important_indices]\n",
    "    test_x = test_x[:, important_indices]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_filter(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    k: int = 50,\n",
    "):\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    selector.fit(train_x, train_y)\n",
    "\n",
    "    train_x = selector.transform(train_x)\n",
    "    valid_x = selector.transform(valid_x)\n",
    "    test_x = selector.transform(test_x)\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_proba(model, test_x, output_path_proba):\n",
    "    proba = model.predict_proba(test_x)\n",
    "\n",
    "    if isinstance(proba, pd.DataFrame):\n",
    "        proba = proba.values\n",
    "\n",
    "    np.savetxt(\n",
    "        output_path_proba,\n",
    "        proba[:, 1],\n",
    "        delimiter=\"\\n\",\n",
    "        header='\"313201_313212\"',\n",
    "        comments=\"\",\n",
    "        # fmt=\"%.19f\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_model(model, output_path_model):\n",
    "    joblib.dump(model, output_path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "\n",
    "def perform_feature_selection(\n",
    "    train_x, train_y, valid_x, test_x, n_features_to_select=None\n",
    "):\n",
    "    estimator_et = ExtraTreesClassifier()\n",
    "    rfe_et = RFE(estimator=estimator_et, n_features_to_select=250)\n",
    "    rfe_et.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfe_et.support_]\n",
    "    valid_x = valid_x[:, rfe_et.support_]\n",
    "    test_x = test_x[:, rfe_et.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    estimator_rf = RandomForestClassifier()\n",
    "    rfe_rf = RFE(estimator=estimator_rf, n_features_to_select=125)\n",
    "    rfe_rf.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfe_rf.support_]\n",
    "    valid_x = valid_x[:, rfe_rf.support_]\n",
    "    test_x = test_x[:, rfe_rf.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    rfecv_et = RFECV(estimator=estimator_et, cv=3, min_features_to_select=25)\n",
    "    rfecv_et.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfecv_et.support_]\n",
    "    valid_x = valid_x[:, rfecv_et.support_]\n",
    "    test_x = test_x[:, rfecv_et.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    rfecv_rf = RFECV(estimator=estimator_rf, cv=3, min_features_to_select=15)\n",
    "    rfecv_rf.fit(train_x, train_y)\n",
    "    train_x = train_x[:, rfecv_rf.support_]\n",
    "    valid_x = valid_x[:, rfecv_rf.support_]\n",
    "    test_x = test_x[:, rfecv_rf.support_]\n",
    "    print(train_x.shape, valid_x.shape, test_x.shape)\n",
    "\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "_test_x = pd.read_table(prefix + \"artificial_test.data\", sep=\" \", header=None)\n",
    "_test_x.drop(_test_x.columns[500], axis=1, inplace=True)\n",
    "_train_y = pd.read_table(prefix + \"artificial_train.labels\", header=None)\n",
    "_train_x = pd.read_table(prefix + \"artificial_train.data\", sep=\" \", header=None)\n",
    "_train_x.drop(_train_x.columns[500], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_x = np.array(_test_x, dtype=float, copy=True)\n",
    "_train_x = np.array(_train_x, dtype=float, copy=True)\n",
    "_train_y = np.array(_train_y, dtype=float, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_x, _train_y = shuffle(_train_x, _train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_validation_data():\n",
    "    split = 400\n",
    "    train_x, valid_x = _train_x[split:].copy(), _train_x[:split].copy()\n",
    "    train_y, valid_y = _train_y[split:].copy(), _train_y[:split].copy()\n",
    "    return train_x, train_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 500) (1600, 1) (400, 500) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, valid_x, valid_y = get_train_and_validation_data()\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 250) (400, 250) (600, 250)\n",
      "(1600, 125) (400, 125) (600, 125)\n",
      "(1600, 26) (400, 26) (600, 26)\n",
      "(1600, 20) (400, 20) (600, 20)\n",
      "(1600, 20) (400, 20) (600, 20)\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, test_x = perform_feature_selection(\n",
    "    train_x, train_y.copy().ravel(), valid_x, _test_x, n_features_to_select=None\n",
    ")\n",
    "print(train_x.shape, valid_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_CORRELATED_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_highly_correlated_features(\n",
    "        train_x, valid_x, _test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_LOW_VARIANCE_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_low_variance_features(train_x, valid_x, test_x)\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_REMOVE_RANDOM_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_random_features(\n",
    "        train_x=train_x, train_y=train_y, valid_x=valid_x, test_x=test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY_ANOVA:\n",
    "    train_x, valid_x, test_x = anova_filter(\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        test_x=test_x,\n",
    "        k=ANOVE_FEATURES,\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)\n",
    "    print(\"valid_x.shape: \", valid_x.shape)\n",
    "    print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 20)\n",
      "train_y.shape:  (1600, 1)\n",
      "valid_x.shape:  (400, 20)\n",
      "valid_y.shape:  (400, 1)\n",
      "test_x.shape:  (600, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x.shape: \", train_x.shape)\n",
    "print(\"train_y.shape: \", train_y.shape)\n",
    "print(\"valid_x.shape: \", valid_x.shape)\n",
    "print(\"valid_y.shape: \", valid_y.shape)\n",
    "print(\"test_x.shape: \", test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "if isinstance(train_x, np.ndarray):\n",
    "    print(\"ok\")\n",
    "if isinstance(train_y, np.ndarray):\n",
    "    print(\"ok\")\n",
    "if isinstance(valid_x, np.ndarray):\n",
    "    print(\"ok\")\n",
    "if isinstance(valid_y, np.ndarray):\n",
    "    print(\"ok\")\n",
    "if isinstance(test_x, np.ndarray):\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7775000\ttotal: 160ms\tremaining: 1m 20s\n",
      "100:\tlearn: 0.9162500\ttotal: 536ms\tremaining: 2.12s\n",
      "200:\tlearn: 0.9418750\ttotal: 900ms\tremaining: 1.34s\n",
      "300:\tlearn: 0.9631250\ttotal: 1.24s\tremaining: 823ms\n",
      "400:\tlearn: 0.9775000\ttotal: 1.59s\tremaining: 392ms\n",
      "499:\tlearn: 0.9862500\ttotal: 1.93s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;stacked_ensemble_1&#x27;,\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[(&#x27;mlp&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              (&#x27;mlpclassifier&#x27;,\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver=&#x27;lbfgs&#x27;,\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             (&#x27;rf&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;stacked_ensemble_1&#x27;,\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[(&#x27;mlp&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              (&#x27;mlpclassifier&#x27;,\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver=&#x27;lbfgs&#x27;,\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             (&#x27;rf&#x27;,\n",
       "                                                              Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>stacked_ensemble_1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>stacked_ensemble_2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=30, min_samples_leaf=2,\n",
       "                           min_samples_split=5, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=30, min_samples_leaf=2,\n",
       "                           min_samples_split=5, n_estimators=500,\n",
       "                           random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>et</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                     random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=500,\n",
       "                       random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, early_stopping=True,\n",
       "              hidden_layer_sizes=(100, 300, 200, 100), max_iter=1000,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.001)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000021568209880&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False,\n",
       "              eval_metric=&lt;function balanced_accuracy_score at 0x000002155619C790&gt;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('stacked_ensemble_1',\n",
       "                              StackingClassifier(cv=5,\n",
       "                                                 estimators=[('mlp',\n",
       "                                                              Pipeline(steps=[('standardscaler',\n",
       "                                                                               StandardScaler()),\n",
       "                                                                              ('mlpclassifier',\n",
       "                                                                               MLPClassifier(alpha=0.001,\n",
       "                                                                                             early_stopping=True,\n",
       "                                                                                             hidden_layer_sizes=(100,\n",
       "                                                                                                                 300,\n",
       "                                                                                                                 200,\n",
       "                                                                                                                 100),\n",
       "                                                                                             max_iter=1000,\n",
       "                                                                                             random_state=42,\n",
       "                                                                                             solver='lbfgs',\n",
       "                                                                                             tol=0.001))])),\n",
       "                                                             ('rf',\n",
       "                                                              Pipeline(steps=[('standardscaler',\n",
       "                                                                               Stan...\n",
       "                                                             grow_policy=None,\n",
       "                                                             importance_type=None,\n",
       "                                                             interaction_constraints=None,\n",
       "                                                             learning_rate=0.02,\n",
       "                                                             max_bin=None,\n",
       "                                                             max_cat_threshold=None,\n",
       "                                                             max_cat_to_onehot=None,\n",
       "                                                             max_delta_step=None,\n",
       "                                                             max_depth=6,\n",
       "                                                             max_leaves=None,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints=None,\n",
       "                                                             multi_strategy=None,\n",
       "                                                             n_estimators=500,\n",
       "                                                             n_jobs=None,\n",
       "                                                             num_parallel_tree=None,\n",
       "                                                             random_state=42, ...))]))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "base_classifiers_1 = [\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"rf\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "base_classifiers_2 = [\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GradientBoostingClassifier(\n",
    "                random_state=SEED,\n",
    "                max_features=None,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=5,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "stacked_ensamble_1 = StackingClassifier(\n",
    "    estimators=base_classifiers_1, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "\n",
    "stacked_ensamble_2 = StackingClassifier(\n",
    "    estimators=base_classifiers_2, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "\n",
    "committee_models = [\n",
    "    (\"stacked_ensemble_1\", stacked_ensamble_1),\n",
    "    (\"stacked_ensemble_2\", stacked_ensamble_2),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GradientBoostingClassifier(\n",
    "                random_state=SEED,\n",
    "                max_features=None,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=2,\n",
    "                min_samples_split=5,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\"et\", make_pipeline(StandardScaler(), ExtraTreesClassifier(\n",
    "        random_state=SEED,\n",
    "        n_estimators=500,\n",
    "        max_depth=30,\n",
    "        min_samples_leaf=4,\n",
    "        min_samples_split=2,\n",
    "        ))),\n",
    "    (\n",
    "        \"rf\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(\n",
    "                random_state=SEED,\n",
    "                n_estimators=500,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=4,\n",
    "                min_samples_split=2,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                early_stopping=True,\n",
    "                tol=1e-3,\n",
    "                solver=\"lbfgs\",\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "                alpha=0.001,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"cb\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            CatBoostClassifier(\n",
    "                iterations=500,\n",
    "                learning_rate=0.03,\n",
    "                depth=6,\n",
    "                l2_leaf_reg=3,\n",
    "                border_count=32,\n",
    "                cat_features=None,\n",
    "                loss_function=\"Logloss\",\n",
    "                eval_metric=\"Accuracy\",\n",
    "                random_seed=SEED,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=100,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"xgb\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            XGBClassifier(\n",
    "                random_state=SEED,\n",
    "                use_label_encoder=False,\n",
    "                eval_metric=balanced_accuracy_score,\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.02,\n",
    "                max_depth=6,\n",
    "                min_child_weight=1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                gamma=0,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=1.0,\n",
    "                scale_pos_weight=1,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score, cross_validate\n",
    "# from sklearn.metrics import make_scorer\n",
    "# balanced_accuracy_scorer = make_scorer(balanced_accuracy_score)\n",
    "# results = cross_validate(committee_model, train_x, train_y.ravel(), cv=5, scoring=balanced_accuracy_scorer)\n",
    "# print(\"Cross-validation results: \", results)\n",
    "\n",
    "committee_model = VotingClassifier(committee_models, voting=\"soft\")\n",
    "committee_model.fit(train_x.copy(), train_y.copy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Balanced Accuracy: 0.8999774949363607\n"
     ]
    }
   ],
   "source": [
    "y_pred = committee_model.predict(valid_x)\n",
    "balanced_accuracy = balanced_accuracy_score(valid_y, y_pred)\n",
    "\n",
    "print(f\"Model Balanced Accuracy: {balanced_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_proba = path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model_proba.txt\")\n",
    "output_path_model = path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model.pkl\")\n",
    "dump_proba(committee_model, test_x, output_path_proba)\n",
    "dump_model(committee_model, output_path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 21) (400, 21)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.concatenate((train_x.copy(), train_y.copy()), axis=1)\n",
    "train_data_pd = pd.DataFrame(train_data, copy=True)\n",
    "train_data_pd.rename(columns={train_data_pd.columns[-1]: \"class\"}, inplace=True)\n",
    "\n",
    "valid_data = np.concatenate((valid_x.copy(), valid_y.copy()), axis=1)\n",
    "valid_data_pd = pd.DataFrame(data=valid_data, copy=True)\n",
    "valid_data_pd.rename(columns={valid_data_pd.columns[-1]: \"class\"}, inplace=True)\n",
    "\n",
    "print(train_data_pd.shape, valid_data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was trained during hyperparameter tuning NeuralNetTorch_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 74.42s of the -621.65s of remaining time.\n",
      "\tFitting 15 child models (S1F1 - S1F15) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.8994\t = Validation score   (balanced_accuracy)\n",
      "\t31.01s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Completed 1/25 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the -664.37s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1\\T19': 1.0}\n",
      "\t0.9056\t = Validation score   (balanced_accuracy)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Completed 1/25 k-fold bagging repeats ...\n",
      "No base models to train on, skipping auxiliary stack level 3...\n",
      "No base models to train on, skipping stack level 3...\n",
      "No base models to train on, skipping auxiliary stack level 4...\n",
      "No base models to train on, skipping stack level 4...\n",
      "Fitting model: WeightedEnsemble_ALL_L5 ... Training model for up to 360.0s of the -667.57s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1\\T19': 1.0}\n",
      "\t0.9056\t = Validation score   (balanced_accuracy)\n",
      "\t2.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "No base models to train on, skipping auxiliary stack level 5...\n",
      "AutoGluon training complete, total runtime = 3896.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"output\\autogluon\\20240114_145731\")\n"
     ]
    }
   ],
   "source": [
    "save_path = path.join(OUTPUT_DIR_AUTOGLUON, UNIQUE_ID)\n",
    "predictor = TabularPredictor(\n",
    "    label=\"class\",\n",
    "    path=save_path,\n",
    "    eval_metric=\"balanced_accuracy\",\n",
    "    problem_type=\"binary\",\n",
    ").fit(\n",
    "    train_data=train_data_pd,\n",
    "    time_limit=TRAIN_TIME_LIMIT_AUTOGLUON,\n",
    "    presets=\"best_quality\",\n",
    "    hyperparameters=\"default\",\n",
    "    fit_weighted_ensemble=True,\n",
    "    fit_full_last_level_weighted_ensemble=True,\n",
    "    full_weighted_ensemble_additionally=True,\n",
    "    num_bag_folds=15,\n",
    "    num_bag_sets=25,\n",
    "    num_stack_levels=3,\n",
    "    auto_stack=True,\n",
    "    dynamic_stacking=True,\n",
    "    feature_generator=\"auto\",\n",
    "    hyperparameter_tune_kwargs={\n",
    "        \"scheduler\": \"local\",\n",
    "        \"searcher\": \"auto\",\n",
    "        \"time_out\": 1200,\n",
    "        \"num_trials\": 30,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1\\T19</td>\n",
       "      <td>0.905649</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.773090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.773090</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.905649</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>114.366095</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>2.593004</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_ALL_L5</td>\n",
       "      <td>0.905649</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>114.320091</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>2.547000</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L1\\T14</td>\n",
       "      <td>0.902513</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.769992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.769992</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT_BAG_L1\\T2</td>\n",
       "      <td>0.901904</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.887532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.887532</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>XGBoost_BAG_L1\\T14</td>\n",
       "      <td>0.850625</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.261424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.261424</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>LightGBMXT_BAG_L1\\T12</td>\n",
       "      <td>0.838790</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.204720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.204720</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>LightGBMXT_BAG_L1\\T15</td>\n",
       "      <td>0.830681</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.520986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.520986</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>LightGBMXT_BAG_L1\\T25</td>\n",
       "      <td>0.803766</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.606920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.606920</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>XGBoost_BAG_L1\\T21</td>\n",
       "      <td>0.795081</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>36.090863</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>36.090863</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  score_val        eval_metric  pred_time_val  \\\n",
       "0        CatBoost_BAG_L1\\T19   0.905649  balanced_accuracy       0.000000   \n",
       "1        WeightedEnsemble_L2   0.905649  balanced_accuracy       0.005999   \n",
       "2    WeightedEnsemble_ALL_L5   0.905649  balanced_accuracy       0.009055   \n",
       "3        CatBoost_BAG_L1\\T14   0.902513  balanced_accuracy       0.000000   \n",
       "4       LightGBMXT_BAG_L1\\T2   0.901904  balanced_accuracy       0.000000   \n",
       "..                       ...        ...                ...            ...   \n",
       "113       XGBoost_BAG_L1\\T14   0.850625  balanced_accuracy       0.000000   \n",
       "114    LightGBMXT_BAG_L1\\T12   0.838790  balanced_accuracy       0.000000   \n",
       "115    LightGBMXT_BAG_L1\\T15   0.830681  balanced_accuracy       0.000000   \n",
       "116    LightGBMXT_BAG_L1\\T25   0.803766  balanced_accuracy       0.000000   \n",
       "117       XGBoost_BAG_L1\\T21   0.795081  balanced_accuracy       0.001000   \n",
       "\n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0    111.773090                0.000000         111.773090            1   \n",
       "1    114.366095                0.005999           2.593004            2   \n",
       "2    114.320091                0.009055           2.547000            5   \n",
       "3    103.769992                0.000000         103.769992            1   \n",
       "4     27.887532                0.000000          27.887532            1   \n",
       "..          ...                     ...                ...          ...   \n",
       "113   30.261424                0.000000          30.261424            1   \n",
       "114   26.204720                0.000000          26.204720            1   \n",
       "115   26.520986                0.000000          26.520986            1   \n",
       "116   26.606920                0.000000          26.606920            1   \n",
       "117   36.090863                0.001000          36.090863            1   \n",
       "\n",
       "     can_infer  fit_order  \n",
       "0         True         83  \n",
       "1         True        117  \n",
       "2         True        118  \n",
       "3         True         78  \n",
       "4         True          4  \n",
       "..         ...        ...  \n",
       "113       True         99  \n",
       "114       True         14  \n",
       "115       True         17  \n",
       "116       True         27  \n",
       "117       True        106  \n",
       "\n",
       "[118 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balanced_accuracy': 0.884899102298017,\n",
       " 'accuracy': 0.885,\n",
       " 'mcc': 0.7699522451097641,\n",
       " 'roc_auc': 0.9496886799529896,\n",
       " 'f1': 0.8826530612244897,\n",
       " 'precision': 0.8871794871794871,\n",
       " 'recall': 0.8781725888324873}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(valid_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_proba = path.join(\n",
    "    OUTPUT_DIR_AUTOGLUON, UNIQUE_ID, \"autogluon_model_proba.txt\"\n",
    ")\n",
    "dump_proba(predictor, pd.DataFrame(test_x), output_path_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLJar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...  1. -1. -1.]\n",
      "AutoML directory: output\\mljar\\20240114_145731\\tmp\n",
      "The task is binary_classification with evaluation metric f1\n",
      "AutoML will use algorithms: ['Decision Tree', 'Linear', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree f1 0.702703 trained in 4.44 seconds\n",
      "Adjust validation. Remove: 1_DecisionTree\n",
      "Validation strategy: 10-fold CV Shuffle,Stratify\n",
      "* Step simple_algorithms will try to check up to 4 models\n",
      "1_DecisionTree f1 0.749035 trained in 7.69 seconds\n",
      "2_DecisionTree f1 0.65162 trained in 7.44 seconds\n",
      "3_DecisionTree f1 0.640741 trained in 8.33 seconds\n",
      "4_Linear f1 0.602484 trained in 18.75 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "5_Default_LightGBM f1 0.882861 trained in 30.44 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_Default_Xgboost f1 0.862305 trained in 31.16 seconds\n",
      "7_Default_CatBoost f1 0.884184 trained in 18.16 seconds\n",
      "8_Default_NeuralNetwork f1 0.864831 trained in 17.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9_Default_RandomForest f1 0.823602 trained in 24.34 seconds\n",
      "10_Default_ExtraTrees f1 0.769231 trained in 18.15 seconds\n",
      "11_Default_NearestNeighbors f1 0.871411 trained in 8.93 seconds\n",
      "* Step not_so_random will try to check up to 61 models\n",
      "21_LightGBM f1 0.882426 trained in 21.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_Xgboost f1 0.860377 trained in 26.64 seconds\n",
      "30_CatBoost f1 0.891386 trained in 21.74 seconds\n",
      "39_RandomForest f1 0.848823 trained in 24.76 seconds\n",
      "48_ExtraTrees f1 0.85625 trained in 24.29 seconds\n",
      "57_NeuralNetwork f1 0.825955 trained in 17.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\supervised\\utils\\learning_curves.py:113: FutureWarning: The behavior of Series.argmax/argmin with skipna=False and NAs, or with all-NAs is deprecated. In a future version this will raise ValueError.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66_NearestNeighbors f1 0.880597 trained in 9.36 seconds\n",
      "22_LightGBM f1 0.875 trained in 26.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "c:\\Users\\YanPC\\Desktop\\automl_hw2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML(\n",
    "    mode=\"Compete\",\n",
    "    ml_task=\"binary_classification\",\n",
    "    total_time_limit=TRAIN_TIME_LIMIT_MLJAR,\n",
    "    eval_metric=\"f1\",\n",
    "    random_state=SEED,\n",
    "    results_path=path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID, \"tmp\"),\n",
    ")\n",
    "train_y = train_y.copy().reshape(-1)\n",
    "print(train_y)\n",
    "automl.fit(train_x.copy(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = AutoML(\n",
    "    mode=\"Compete\",\n",
    "    ml_task=\"binary_classification\",\n",
    "    total_time_limit=TRAIN_TIME_LIMIT_MLJAR,\n",
    "    eval_metric=\"f1\",\n",
    "    random_state=SEED,\n",
    "    results_path=\"output\\\\mljar\\\\20240114_002215\",\n",
    ")\n",
    "\n",
    "print(valid_x.shape, valid_y.shape)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "predictions = loaded.predict_proba(valid_x.copy().reshape(-1))\n",
    "\n",
    "score = balanced_accuracy_score(valid_y, predictions)\n",
    "\n",
    "print(f\"Model Balanced Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID, \"mljar_model_proba.txt\")\n",
    "dump_proba(automl, test_x, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(X, model1, model2):\n",
    "    pred1 = model1.predict_proba(pd.DataFrame(X)).values[:, 1]\n",
    "    pred2 = model2.predict_proba(X)[:, 1]\n",
    "    print(pred1, pred2)\n",
    "    avg_pred = (pred1 + pred2) / 2\n",
    "\n",
    "    return avg_pred\n",
    "\n",
    "\n",
    "final_predictions = ensemble_predict(test_x, predictor, automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path.join(\"ensamble\", UNIQUE_ID), exist_ok=True)\n",
    "\n",
    "np.savetxt(\n",
    "    path.join(\"ensamble\", UNIQUE_ID, \"123manual_model_pred.txt\"),\n",
    "    final_predictions,\n",
    "    delimiter=\"\\n\",\n",
    "    comments=\"\",\n",
    "    header='\"313201\"',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
