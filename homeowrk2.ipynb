{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mljar-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from os import path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, f_classif\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, mutual_info_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from supervised.automl import AutoML  # mljar-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "SEED = 42\n",
    "N_JOBS = -1\n",
    "RANDOM_SEARCH_N_ITER = 50\n",
    "TRAIN_TIME_LIMIT_AUTOGLUON = 60 * 30\n",
    "TRAIN_TIME_LIMIT_MLJAR = 60 * 30\n",
    "TRAIN_TIME_LIMIT_AUTO_SKLEARN = 60 * 30\n",
    "OUTPUT_DIR_MANUAL = path.join(\"output\", \"manual\")\n",
    "OUTPUT_DIR_AUTOGLUON = path.join(\"output\", \"autogluon\")\n",
    "OUTPUT_DIR_MLJAR = path.join(\"output\", \"mljar\")\n",
    "OUTPUT_DIR_AUTO_SKLEARN = path.join(\"output\", \"auto_sklearn\")\n",
    "UNIQUE_ID = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "APPLY_REMOVE_LOW_VARIANCE_FEATURES = True\n",
    "APPLY_REMOVE_CORRELATED_FEATURES = True\n",
    "APPLY_REMOVE_RANDOM_FEATURES = True\n",
    "APPLY_ANOVA = True\n",
    "ANOVE_FEATURES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output directory output\\manual\\20240111_191521\n",
      "Creating output directory output\\autogluon\\20240111_191521\n",
      "Creating output directory output\\mljar\\20240111_191521\n",
      "Creating output directory output\\auto_sklearn\\20240111_191521\n"
     ]
    }
   ],
   "source": [
    "# prepare output directories\n",
    "for output_dir in [\n",
    "    OUTPUT_DIR_MANUAL,\n",
    "    OUTPUT_DIR_AUTOGLUON,\n",
    "    OUTPUT_DIR_MLJAR,\n",
    "    OUTPUT_DIR_AUTO_SKLEARN,\n",
    "]:\n",
    "    if not path.exists(path.join(output_dir, UNIQUE_ID)):\n",
    "        print(f\"Creating output directory {path.join(output_dir, UNIQUE_ID)}\")\n",
    "        os.makedirs(path.join(output_dir, UNIQUE_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Highly Correlated Columns\n",
    "# def remove_highly_correlated_features(train_x, valid_x, test_x, threshold=0.95):\n",
    "#     corr_matrix = np.corrcoef(train_x, rowvar=False)\n",
    "#     upper = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "#     to_drop = np.where(np.abs(corr_matrix[upper]) > threshold)[0]\n",
    "#     print(to_drop)\n",
    "#     train_x = np.delete(train_x, to_drop, axis=1)\n",
    "#     valid_x = np.delete(valid_x, to_drop, axis=1)\n",
    "#     test_x = np.delete(test_x, to_drop, axis=1)\n",
    "#     return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def remove_highly_correlated_features(train_x, valid_x, test_x, threshold=0.95):\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = np.corrcoef(train_x, rowvar=False)\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = np.triu(corr_matrix, k=1)\n",
    "    # Find indices of feature columns with correlation greater than threshold\n",
    "    to_drop = [i for i in range(upper.shape[1]) if any(upper[:, i] > threshold)]\n",
    "\n",
    "    # Drop features from train, validation, and test set\n",
    "    train_x = np.delete(train_x, to_drop, axis=1)\n",
    "    valid_x = np.delete(valid_x, to_drop, axis=1)\n",
    "    test_x = np.delete(test_x, to_drop, axis=1)\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "# pandas\n",
    "# # Remove Highly Correlated Columns\n",
    "# def remove_highly_correlated_features(train_x, valid_x, text_x, threshold=0.95):\n",
    "#     corr_matrix = train_x.corr().abs()\n",
    "#     # Select upper triangle of correlation matrix\n",
    "#     upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "#     # Find index of feature columns with correlation greater than threshold\n",
    "#     to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "#     train_x = train_x.drop(to_drop, axis=1)\n",
    "#     valid_x = valid_x.drop(to_drop, axis=1)\n",
    "#     text_x = text_x.drop(to_drop, axis=1)\n",
    "#     return train_x, valid_x, text_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Low Variance Columns\n",
    "def remove_low_variance_features(train_x, valid_x, test_x, threshold=(0.8 * (1 - 0.8))):\n",
    "    sel = VarianceThreshold(threshold=threshold)\n",
    "    sel.fit(train_x)\n",
    "    train_x = train_x[:, sel.get_support(indices=True)]\n",
    "    valid_x = valid_x[:, sel.get_support(indices=True)]\n",
    "    test_x = test_x[:, sel.get_support(indices=True)]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Random Columns\n",
    "def remove_random_features(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    importance=0.005,\n",
    "):\n",
    "    tree: DecisionTreeClassifier = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(train_x, train_y)\n",
    "    importances = tree.feature_importances_\n",
    "\n",
    "    # Assume columns with very low importance are \"random\"\n",
    "    # This threshold can be adjusted based on domain knowledge\n",
    "    important_indices = [i for i, imp in enumerate(importances) if imp > importance]\n",
    "    train_x = train_x[:, important_indices]\n",
    "    valid_x = valid_x[:, important_indices]\n",
    "    test_x = test_x[:, important_indices]\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_filter(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    valid_x: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    k: int = 50,\n",
    "):\n",
    "    # Using ANOVA F-test to select features\n",
    "    selector = SelectKBest(\n",
    "        f_classif, k=k\n",
    "    )  # Change k to select the number of features you want\n",
    "    selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get F-values and p-values for each feature\n",
    "    # f_values = selector.scores_\n",
    "    # p_values = selector.pvalues_\n",
    "\n",
    "    # Selecting features (you can use a threshold or select top k features)\n",
    "    # selected_features = train_x.columns[selector.get_support()]\n",
    "\n",
    "    # Transforming train_x to include only the selected features\n",
    "    train_x = selector.transform(train_x)\n",
    "    valid_x = selector.transform(valid_x)\n",
    "    test_x = selector.transform(test_x)\n",
    "    return train_x, valid_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "_test_x = pd.read_table(prefix + \"artificial_test.data\", sep=\" \", header=None)\n",
    "_test_x.drop(_test_x.columns[500], axis=1, inplace=True)\n",
    "_train_y = pd.read_table(prefix + \"artificial_train.labels\", header=None)\n",
    "_train_x = pd.read_table(prefix + \"artificial_train.data\", sep=\" \", header=None)\n",
    "_train_x.drop(_train_x.columns[500], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_x, _train_y = shuffle(_train_x, _train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_validation_data():\n",
    "    split = 400\n",
    "    train_x, valid_x = _train_x[split:].values, _train_x[:split].values\n",
    "    train_y, valid_y = _train_y[split:].values, _train_y[:split].values\n",
    "    return train_x, train_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 500) (1600, 1) (400, 500) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, valid_x, valid_y = get_train_and_validation_data()\n",
    "train_y = train_y.reshape(-1, 1)\n",
    "valid_y = valid_y.reshape(-1, 1)\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 490)\n"
     ]
    }
   ],
   "source": [
    "if APPLY_REMOVE_CORRELATED_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_highly_correlated_features(\n",
    "        train_x, valid_x, _test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 490)\n"
     ]
    }
   ],
   "source": [
    "if APPLY_REMOVE_LOW_VARIANCE_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_low_variance_features(train_x, valid_x, test_x)\n",
    "    print(\"train_x.shape: \", train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 40)\n"
     ]
    }
   ],
   "source": [
    "if APPLY_REMOVE_RANDOM_FEATURES:\n",
    "    train_x, valid_x, test_x = remove_random_features(\n",
    "        train_x=train_x, train_y=train_y, valid_x=valid_x, test_x=test_x\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "if APPLY_ANOVA:\n",
    "    train_x, valid_x, test_x = anova_filter(\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        test_x=test_x,\n",
    "        k=ANOVE_FEATURES,\n",
    "    )\n",
    "    print(\"train_x.shape: \", train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "# train_x = pd.DataFrame(train_x)\n",
    "# valid_x = pd.DataFrame(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  (1600, 10)\n",
      "train_y.shape:  (1600, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x.shape: \", train_x.shape)\n",
    "print(\"train_y.shape: \", train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = \"class\"\n",
    "# train_y = train_y.rename(columns={0: label})\n",
    "# valid_y = valid_y.rename(columns={0: label})\n",
    "# train_data = pd.concat([train_x, train_y[label]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "(\n",
    "    original_train_x,\n",
    "    original_train_y,\n",
    "    original_valid_x,\n",
    "    original_valid_y,\n",
    ") = get_train_and_validation_data()\n",
    "for y, original_y in zip([train_y, valid_y], [original_train_y, original_valid_y]):\n",
    "    assert y.shape == original_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = train_y.ravel()\n",
    "# valid_y = valid_y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Model Balanced Accuracy: 0.8572803880873197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "base_classifiers_1 = [\n",
    "    (\n",
    "        \"rf\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            RandomForestClassifier(n_estimators=100, random_state=SEED),\n",
    "        ),\n",
    "    ),\n",
    "    (\"svc\", make_pipeline(StandardScaler(), SVC(random_state=SEED))),\n",
    "    (\"dt\", make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=SEED))),\n",
    "    (\n",
    "        \"elasticnet\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            ElasticNet(\n",
    "                alpha=0.0001, l1_ratio=0.15, max_iter=1000, tol=1e-3, random_state=SEED\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                tol=1e-3,\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=SEED)),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# First Stacking Layer\n",
    "first_layer = StackingClassifier(\n",
    "    estimators=base_classifiers_1, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "\n",
    "base_classifiers_2 = [\n",
    "    (\"first_layer\", first_layer),\n",
    "    (\n",
    "        \"mlp\",\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MLPClassifier(\n",
    "                random_state=SEED,\n",
    "                max_iter=1000,\n",
    "                tol=1e-3,\n",
    "                hidden_layer_sizes=(100, 300, 200, 100),\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"gbc\",\n",
    "        make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=SEED)),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "param_distributions = {\n",
    "    # Parameters for the First Stacking Layer\n",
    "    \"first_layer__rf__randomforestclassifier__n_estimators\": randint(50, 200),\n",
    "    \"first_layer__rf__randomforestclassifier__max_depth\": randint(15, 50),\n",
    "    \"first_layer__rf__randomforestclassifier__min_samples_split\": randint(4, 20),\n",
    "    \"first_layer__rf__randomforestclassifier__min_samples_leaf\": randint(4, 20),\n",
    "    \"first_layer__svc__svc__C\": uniform(0.1, 10),\n",
    "    \"first_layer__svc__svc__gamma\": [\"scale\", \"auto\"],\n",
    "    \"first_layer__dt__decisiontreeclassifier__max_depth\": randint(15, 50),\n",
    "    \"first_layer__dt__decisiontreeclassifier__min_samples_split\": randint(5, 20),\n",
    "    \"first_layer__dt__decisiontreeclassifier__min_samples_leaf\": randint(5, 20),\n",
    "    \"first_layer__elasticnet__elasticnet__alpha\": uniform(0.0001, 1),\n",
    "    \"first_layer__elasticnet__elasticnet__l1_ratio\": uniform(0, 1),\n",
    "    \"first_layer__mlp__mlpclassifier__alpha\": uniform(0.0001, 1),\n",
    "    \"first_layer__mlp__mlpclassifier__learning_rate_init\": uniform(0.001, 0.1),\n",
    "    \"first_layer__mlp__mlpclassifier__hidden_layer_sizes\": [\n",
    "        (50, 40),\n",
    "        (50, 100, 50),\n",
    "        (50, 150, 100, 50),\n",
    "    ],\n",
    "    # Parameters for the Second Stacking Layer\n",
    "    \"mlp__mlpclassifier__alpha\": uniform(0.0001, 1),\n",
    "    \"mlp__mlpclassifier__learning_rate_init\": uniform(0.001, 0.1),\n",
    "    \"mlp__mlpclassifier__hidden_layer_sizes\": [\n",
    "        (50, 40),\n",
    "        (50, 100, 50),\n",
    "        (50, 150, 100, 50),\n",
    "    ],\n",
    "    \"gbc__gradientboostingclassifier__n_estimators\": randint(50, 200),\n",
    "    \"gbc__gradientboostingclassifier__max_depth\": randint(15, 50),\n",
    "    \"gbc__gradientboostingclassifier__min_samples_split\": randint(4, 20),\n",
    "    \"gbc__gradientboostingclassifier__min_samples_leaf\": randint(4, 20),\n",
    "    # Parameters for the Final Estimator\n",
    "    \"final_estimator__C\": uniform(0.01, 10),\n",
    "}\n",
    "\n",
    "\n",
    "# Second Stacking Layer\n",
    "stacked_ensemble_model = StackingClassifier(\n",
    "    estimators=base_classifiers_2, final_estimator=LogisticRegression(), cv=5\n",
    ")\n",
    "# Define the committee of models\n",
    "committee_models = [\n",
    "    (\"stacked_ensemble\", stacked_ensemble_model),\n",
    "    (\"gbc\", GradientBoostingClassifier(random_state=SEED)),\n",
    "    (\"rf\", RandomForestClassifier(random_state=SEED))\n",
    "]\n",
    "\n",
    "# Create the committee model\n",
    "committee_model = VotingClassifier(committee_models)\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    committee_model,\n",
    "    param_distributions=param_distributions,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_iter=RANDOM_SEARCH_N_ITER,\n",
    "    cv=5,\n",
    "    verbose=4,\n",
    "    random_state=SEED,\n",
    "    n_jobs=8,\n",
    ")\n",
    "\n",
    "random_search.fit(train_x, train_y)\n",
    "\n",
    "y_pred = random_search.predict(valid_x)\n",
    "\n",
    "balanced_accuracy = balanced_accuracy_score(valid_y, y_pred)\n",
    "\n",
    "print(f\"Model Balanced Accuracy: {balanced_accuracy}\")\n",
    "\n",
    "\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     stacked_ensemble_model,\n",
    "#     param_distributions=param_distributions,\n",
    "#     scoring=\"balanced_accuracy\",\n",
    "#     n_iter=RANDOM_SEARCH_N_ITER,\n",
    "#     cv=5,\n",
    "#     verbose=4,\n",
    "#     random_state=SEED,\n",
    "#     n_jobs=8,\n",
    "# )\n",
    "\n",
    "# random_search.fit(train_x, train_y)\n",
    "\n",
    "# y_pred = random_search.predict(valid_x)\n",
    "\n",
    "# balanced_accuracy = balanced_accuracy_score(valid_y, y_pred)\n",
    "\n",
    "# print(f\"Model Balanced Accuracy: {balanced_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_estimator__C': 1.962429877980445, 'first_layer__dt__decisiontreeclassifier__max_depth': 33, 'first_layer__dt__decisiontreeclassifier__min_samples_leaf': 8, 'first_layer__dt__decisiontreeclassifier__min_samples_split': 7, 'first_layer__elasticnet__elasticnet__alpha': 0.768654014306309, 'first_layer__elasticnet__elasticnet__l1_ratio': 0.04360377175443375, 'first_layer__mlp__mlpclassifier__alpha': 0.994650510797341, 'first_layer__mlp__mlpclassifier__hidden_layer_sizes': (50, 100, 50), 'first_layer__mlp__mlpclassifier__learning_rate_init': 0.09639285770025874, 'first_layer__rf__randomforestclassifier__max_depth': 20, 'first_layer__rf__randomforestclassifier__min_samples_leaf': 6, 'first_layer__rf__randomforestclassifier__min_samples_split': 15, 'first_layer__rf__randomforestclassifier__n_estimators': 86, 'first_layer__svc__svc__C': 9.383185625877253, 'first_layer__svc__svc__gamma': 'scale', 'gbc__gradientboostingclassifier__max_depth': 45, 'gbc__gradientboostingclassifier__min_samples_leaf': 6, 'gbc__gradientboostingclassifier__min_samples_split': 15, 'gbc__gradientboostingclassifier__n_estimators': 165, 'mlp__mlpclassifier__alpha': 0.2945488920695857, 'mlp__mlpclassifier__hidden_layer_sizes': (50, 40), 'mlp__mlpclassifier__learning_rate_init': 0.020091103115034606}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output\\\\manual\\\\20240111_191521\\\\manual_model_pred.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = random_search.predict_proba(test_x)\n",
    "output_path = path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model.txt\")\n",
    "np.savetxt(output_path, proba[:, 1], delimiter=\"\\n\")\n",
    "joblib.dump(\n",
    "    random_search, path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model_pred.pkl\")\n",
    ")\n",
    "# random_search.save(path.join(OUTPUT_DIR_MANUAL, UNIQUE_ID, \"manual_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10) (1600, 1)\n",
      "(400, 10) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((train_x, train_y), axis=1)\n",
    "train_data_pd = pd.DataFrame(train_data)\n",
    "train_data_pd.rename(columns={train_data_pd.columns[-1]: \"class\"}, inplace=True)\n",
    "\n",
    "valid_data = np.concatenate((valid_x, valid_y), axis=1)\n",
    "valid_data_pd = pd.DataFrame(valid_data)\n",
    "valid_data_pd.rename(columns={valid_data_pd.columns[-1]: \"class\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 11) (400, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_pd.shape, valid_data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"output\\autogluon\\20240111_191521\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 1800 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: output\\autogluon\\20240111_191521/ds_sub_fit/sub_fit_ho.\n",
      "2024-01-11 20:44:47,880\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Beginning AutoGluon training ... Time limit = 450s\n",
      "AutoGluon will save models to \"output\\autogluon\\20240111_191521/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.90 GB / 15.71 GB (43.9%)\n",
      "Disk Space Avail:   57.40 GB / 357.30 GB (16.1%)\n",
      "===================================================\n",
      "Train Data Rows:    1422\n",
      "Train Data Columns: 10\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7069.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 10 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 10 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 299.87s of the 449.91s of remaining time.\n",
      "\t0.8368\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 299.79s of the 449.83s of remaining time.\n",
      "\t0.8368\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 299.74s of the 449.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8432\t = Validation score   (balanced_accuracy)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 281.91s of the 431.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8544\t = Validation score   (balanced_accuracy)\n",
      "\t3.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 271.27s of the 421.31s of remaining time.\n",
      "\t0.8475\t = Validation score   (balanced_accuracy)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 269.99s of the 420.03s of remaining time.\n",
      "\t0.8404\t = Validation score   (balanced_accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 268.69s of the 418.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8594\t = Validation score   (balanced_accuracy)\n",
      "\t8.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 253.98s of the 404.02s of remaining time.\n",
      "\t0.8475\t = Validation score   (balanced_accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 253.02s of the 403.06s of remaining time.\n",
      "\t0.8447\t = Validation score   (balanced_accuracy)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 252.09s of the 402.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.8544\t = Validation score   (balanced_accuracy)\n",
      "\t10.93s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 235.14s of the 385.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.8474\t = Validation score   (balanced_accuracy)\n",
      "\t2.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 226.13s of the 376.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.8524\t = Validation score   (balanced_accuracy)\n",
      "\t12.84s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 207.31s of the 357.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8622\t = Validation score   (balanced_accuracy)\n",
      "\t6.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 344.4s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesEntr_BAG_L1': 0.2, 'ExtraTreesGini_BAG_L1': 0.175, 'NeuralNetTorch_BAG_L1': 0.125, 'NeuralNetFastAI_BAG_L1': 0.1, 'XGBoost_BAG_L1': 0.1, 'LightGBMLarge_BAG_L1': 0.075, 'KNeighborsDist_BAG_L1': 0.05, 'RandomForestGini_BAG_L1': 0.05, 'CatBoost_BAG_L1': 0.05, 'KNeighborsUnif_BAG_L1': 0.025, 'LightGBM_BAG_L1': 0.025, 'RandomForestEntr_BAG_L1': 0.025}\n",
      "\t0.8812\t = Validation score   (balanced_accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 343.44s of the 343.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.8825\t = Validation score   (balanced_accuracy)\n",
      "\t4.11s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 332.13s of the 332.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.8769\t = Validation score   (balanced_accuracy)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 323.12s of the 323.1s of remaining time.\n",
      "\t0.8657\t = Validation score   (balanced_accuracy)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 321.81s of the 321.79s of remaining time.\n",
      "\t0.8685\t = Validation score   (balanced_accuracy)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 320.66s of the 320.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8833\t = Validation score   (balanced_accuracy)\n",
      "\t11.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 303.29s of the 303.27s of remaining time.\n",
      "\t0.865\t = Validation score   (balanced_accuracy)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 302.09s of the 302.07s of remaining time.\n",
      "\t0.865\t = Validation score   (balanced_accuracy)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 301.03s of the 301.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8714\t = Validation score   (balanced_accuracy)\n",
      "\t8.78s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 285.94s of the 285.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\t0.8783\t = Validation score   (balanced_accuracy)\n",
      "\t6.39s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 272.18s of the 272.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.8805\t = Validation score   (balanced_accuracy)\n",
      "\t11.32s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 254.02s of the 254.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.28%)\n",
      "\t0.8769\t = Validation score   (balanced_accuracy)\n",
      "\t8.44s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 238.99s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.833, 'NeuralNetTorch_BAG_L2': 0.069, 'RandomForestGini_BAG_L1': 0.028, 'CatBoost_BAG_L1': 0.014, 'ExtraTreesEntr_BAG_L1': 0.014, 'LightGBM_BAG_L2': 0.014, 'RandomForestEntr_BAG_L2': 0.014, 'XGBoost_BAG_L2': 0.014}\n",
      "\t0.8847\t = Validation score   (balanced_accuracy)\n",
      "\t1.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 212.54s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"output\\autogluon\\20240111_191521/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                      model  holdout_score  score_val        eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     ExtraTreesEntr_BAG_L2       0.915730   0.864976  balanced_accuracy        1.474391       1.064861  52.750458                 0.091975                0.111674           0.877798            2       True         21\n",
      "1     ExtraTreesEntr_BAG_L1       0.910112   0.844651  balanced_accuracy        0.110983       0.101653   0.770360                 0.110983                0.101653           0.770360            1       True          9\n",
      "2           CatBoost_BAG_L2       0.910112   0.883261  balanced_accuracy        1.396421       0.972254  63.165720                 0.014006                0.019066          11.293060            2       True         19\n",
      "3         LightGBMXT_BAG_L2       0.910112   0.882537  balanced_accuracy        1.415583       0.978460  55.980129                 0.033168                0.025273           4.107470            2       True         15\n",
      "4     NeuralNetTorch_BAG_L2       0.910112   0.880495  balanced_accuracy        1.447558       1.033836  63.197472                 0.065143                0.080649          11.324812            2       True         24\n",
      "5    NeuralNetFastAI_BAG_L2       0.910112   0.871356  balanced_accuracy        1.468632       1.077328  60.647956                 0.086216                0.124141           8.775297            2       True         22\n",
      "6   RandomForestEntr_BAG_L2       0.910112   0.868496  balanced_accuracy        1.475517       1.062088  52.860018                 0.093101                0.108901           0.987358            2       True         18\n",
      "7     ExtraTreesGini_BAG_L2       0.910112   0.864976  balanced_accuracy        1.479006       1.102913  52.851912                 0.096591                0.149725           0.979252            2       True         20\n",
      "8   RandomForestGini_BAG_L2       0.910112   0.865677  balanced_accuracy        1.483042       1.059477  53.006894                 0.100627                0.106289           1.134235            2       True         17\n",
      "9       WeightedEnsemble_L3       0.910112   0.884673  balanced_accuracy        1.718491       1.231676  86.526816                 0.007000                0.002301           1.502600            3       True         26\n",
      "10      WeightedEnsemble_L2       0.898876   0.881202  balanced_accuracy        1.296094       0.843055  49.224513                 0.006999                0.001941           0.919891            2       True         14\n",
      "11          LightGBM_BAG_L2       0.898876   0.876917  balanced_accuracy        1.405906       0.969868  55.032411                 0.023490                0.016681           3.159751            2       True         16\n",
      "12     LightGBMLarge_BAG_L2       0.898876   0.876935  balanced_accuracy        1.545945       1.013202  60.314361                 0.163530                0.060015           8.441701            2       True         25\n",
      "13    NeuralNetTorch_BAG_L1       0.893258   0.852360  balanced_accuracy        0.058763       0.041178  12.836479                 0.058763                0.041178          12.836479            1       True         12\n",
      "14           XGBoost_BAG_L2       0.893258   0.878335  balanced_accuracy        1.515750       1.004079  58.259234                 0.133335                0.050892           6.386575            2       True         23\n",
      "15          CatBoost_BAG_L1       0.893258   0.859368  balanced_accuracy        0.028992       0.014325   8.381136                 0.028992                0.014325           8.381136            1       True          7\n",
      "16  RandomForestGini_BAG_L1       0.887640   0.847458  balanced_accuracy        0.098861       0.124646   1.042100                 0.098861                0.124646           1.042100            1       True          5\n",
      "17    KNeighborsDist_BAG_L1       0.882022   0.836829  balanced_accuracy        0.030102       0.031597   0.006003                 0.030102                0.031597           0.006003            1       True          2\n",
      "18  RandomForestEntr_BAG_L1       0.882022   0.840437  balanced_accuracy        0.094809       0.122908   0.941949                 0.094809                0.122908           0.941949            1       True          6\n",
      "19    ExtraTreesGini_BAG_L1       0.882022   0.847487  balanced_accuracy        0.125321       0.103584   0.777112                 0.125321                0.103584           0.777112            1       True          8\n",
      "20        LightGBMXT_BAG_L1       0.876404   0.843232  balanced_accuracy        0.093320       0.112074   3.568038                 0.093320                0.112074           3.568038            1       True          3\n",
      "21    KNeighborsUnif_BAG_L1       0.870787   0.836835  balanced_accuracy        0.022426       0.041369   0.005260                 0.022426                0.041369           0.005260            1       True          1\n",
      "22          LightGBM_BAG_L1       0.865169   0.854449  balanced_accuracy        0.043286       0.043608   3.358933                 0.043286                0.043608           3.358933            1       True          4\n",
      "23     LightGBMLarge_BAG_L1       0.865169   0.862193  balanced_accuracy        0.162702       0.068854   6.581507                 0.162702                0.068854           6.581507            1       True         13\n",
      "24   NeuralNetFastAI_BAG_L1       0.865169   0.854443  balanced_accuracy        0.320685       0.103568  10.925962                 0.320685                0.103568          10.925962            1       True         10\n",
      "25           XGBoost_BAG_L1       0.853933   0.847434  balanced_accuracy        0.192166       0.043824   2.677819                 0.192166                0.043824           2.677819            1       True         11\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 216 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 1584 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 1584s\n",
      "AutoGluon will save models to \"output\\autogluon\\20240111_191521\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.74 GB / 15.71 GB (42.9%)\n",
      "Disk Space Avail:   57.40 GB / 357.30 GB (16.1%)\n",
      "===================================================\n",
      "Train Data Rows:    1600\n",
      "Train Data Columns: 10\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = -1\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (1) vs negative (-1) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6901.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.12 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 10 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 10 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1055.68s of the 1583.91s of remaining time.\n",
      "\t0.8462\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1055.61s of the 1583.84s of remaining time.\n",
      "\t0.8481\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1055.55s of the 1583.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8594\t = Validation score   (balanced_accuracy)\n",
      "\t5.49s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1043.72s of the 1571.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.865\t = Validation score   (balanced_accuracy)\n",
      "\t3.36s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1033.1s of the 1561.34s of remaining time.\n",
      "\t0.8613\t = Validation score   (balanced_accuracy)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1031.89s of the 1560.12s of remaining time.\n",
      "\t0.8557\t = Validation score   (balanced_accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1030.78s of the 1559.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.8681\t = Validation score   (balanced_accuracy)\n",
      "\t12.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1012.25s of the 1540.49s of remaining time.\n",
      "\t0.8482\t = Validation score   (balanced_accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1010.8s of the 1539.03s of remaining time.\n",
      "\t0.8532\t = Validation score   (balanced_accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1009.65s of the 1537.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.8712\t = Validation score   (balanced_accuracy)\n",
      "\t14.22s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 987.95s of the 1516.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.8581\t = Validation score   (balanced_accuracy)\n",
      "\t5.27s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 974.0s of the 1502.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.8706\t = Validation score   (balanced_accuracy)\n",
      "\t21.75s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 945.24s of the 1473.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
      "\t0.8563\t = Validation score   (balanced_accuracy)\n",
      "\t7.79s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1457.56s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L1': 0.214, 'ExtraTreesGini_BAG_L1': 0.214, 'NeuralNetFastAI_BAG_L1': 0.129, 'ExtraTreesEntr_BAG_L1': 0.086, 'RandomForestGini_BAG_L1': 0.071, 'CatBoost_BAG_L1': 0.071, 'NeuralNetTorch_BAG_L1': 0.071, 'KNeighborsUnif_BAG_L1': 0.057, 'KNeighborsDist_BAG_L1': 0.043, 'LightGBMXT_BAG_L1': 0.043}\n",
      "\t0.8875\t = Validation score   (balanced_accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1456.13s of the 1456.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
      "\t0.8881\t = Validation score   (balanced_accuracy)\n",
      "\t2.24s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 1447.0s of the 1446.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.8894\t = Validation score   (balanced_accuracy)\n",
      "\t6.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1432.13s of the 1432.1s of remaining time.\n",
      "\t0.8719\t = Validation score   (balanced_accuracy)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1430.41s of the 1430.39s of remaining time.\n",
      "\t0.8744\t = Validation score   (balanced_accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 1428.82s of the 1428.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8912\t = Validation score   (balanced_accuracy)\n",
      "\t14.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1406.56s of the 1406.53s of remaining time.\n",
      "\t0.875\t = Validation score   (balanced_accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1405.28s of the 1405.25s of remaining time.\n",
      "\t0.8731\t = Validation score   (balanced_accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1404.18s of the 1404.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.875\t = Validation score   (balanced_accuracy)\n",
      "\t10.45s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 1386.56s of the 1386.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.89\t = Validation score   (balanced_accuracy)\n",
      "\t5.54s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1372.77s of the 1372.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.8843\t = Validation score   (balanced_accuracy)\n",
      "\t11.03s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1354.8s of the 1354.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\t0.8906\t = Validation score   (balanced_accuracy)\n",
      "\t8.92s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 1337.6s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.842, 'RandomForestGini_BAG_L1': 0.053, 'RandomForestEntr_BAG_L1': 0.053, 'LightGBMXT_BAG_L2': 0.053}\n",
      "\t0.8919\t = Validation score   (balanced_accuracy)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 248.43s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"output\\autogluon\\20240111_191521\")\n"
     ]
    }
   ],
   "source": [
    "save_path = path.join(OUTPUT_DIR_AUTOGLUON, UNIQUE_ID)\n",
    "predictor = TabularPredictor(\n",
    "    label=\"class\",\n",
    "    path=save_path,\n",
    "    eval_metric=\"balanced_accuracy\",\n",
    "    problem_type=\"binary\",\n",
    ").fit(\n",
    "    train_data_pd,\n",
    "    time_limit=TRAIN_TIME_LIMIT_AUTOGLUON,\n",
    "    presets=\"best_quality\",\n",
    "    hyperparameters=\"default\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.891881</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.303733</td>\n",
       "      <td>93.181199</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>1.990012</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.891248</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.281687</td>\n",
       "      <td>88.950525</td>\n",
       "      <td>0.018195</td>\n",
       "      <td>14.548193</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.890607</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.323258</td>\n",
       "      <td>83.322735</td>\n",
       "      <td>0.059767</td>\n",
       "      <td>8.920403</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.889975</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.308170</td>\n",
       "      <td>79.942836</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>5.540503</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.889366</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.287584</td>\n",
       "      <td>80.495197</td>\n",
       "      <td>0.024093</td>\n",
       "      <td>6.092865</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.888107</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.283041</td>\n",
       "      <td>76.642994</td>\n",
       "      <td>0.019549</td>\n",
       "      <td>2.240662</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.887503</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.076430</td>\n",
       "      <td>59.366956</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>1.384510</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>0.884334</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.323828</td>\n",
       "      <td>85.430761</td>\n",
       "      <td>0.060336</td>\n",
       "      <td>11.028428</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.403416</td>\n",
       "      <td>84.852895</td>\n",
       "      <td>0.139925</td>\n",
       "      <td>10.450563</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.874998</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.436731</td>\n",
       "      <td>75.409857</td>\n",
       "      <td>0.173239</td>\n",
       "      <td>1.007524</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.874390</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.464191</td>\n",
       "      <td>75.704287</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>1.301955</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.873121</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.400434</td>\n",
       "      <td>75.288907</td>\n",
       "      <td>0.136942</td>\n",
       "      <td>0.886575</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.406775</td>\n",
       "      <td>75.909076</td>\n",
       "      <td>0.143283</td>\n",
       "      <td>1.506744</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.871234</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.184011</td>\n",
       "      <td>14.221804</td>\n",
       "      <td>0.184011</td>\n",
       "      <td>14.221804</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.870551</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.060479</td>\n",
       "      <td>21.749640</td>\n",
       "      <td>0.060479</td>\n",
       "      <td>21.749640</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.868097</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>12.415411</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>12.415411</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.865012</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.073308</td>\n",
       "      <td>3.361433</td>\n",
       "      <td>0.073308</td>\n",
       "      <td>3.361433</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.861300</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.118791</td>\n",
       "      <td>1.040795</td>\n",
       "      <td>0.118791</td>\n",
       "      <td>1.040795</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.859436</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.189651</td>\n",
       "      <td>5.492260</td>\n",
       "      <td>0.189651</td>\n",
       "      <td>5.492260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.858139</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.042822</td>\n",
       "      <td>5.266464</td>\n",
       "      <td>0.042822</td>\n",
       "      <td>5.266464</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.856267</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>7.791990</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>7.791990</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.855663</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.117259</td>\n",
       "      <td>0.940482</td>\n",
       "      <td>0.117259</td>\n",
       "      <td>0.940482</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.853191</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.165982</td>\n",
       "      <td>0.885833</td>\n",
       "      <td>0.165982</td>\n",
       "      <td>0.885833</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.848200</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.152776</td>\n",
       "      <td>1.221231</td>\n",
       "      <td>0.152776</td>\n",
       "      <td>1.221231</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.848102</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.846234</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.035699</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.035699</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val        eval_metric  pred_time_val  \\\n",
       "0       WeightedEnsemble_L3   0.891881  balanced_accuracy       1.303733   \n",
       "1           CatBoost_BAG_L2   0.891248  balanced_accuracy       1.281687   \n",
       "2      LightGBMLarge_BAG_L2   0.890607  balanced_accuracy       1.323258   \n",
       "3            XGBoost_BAG_L2   0.889975  balanced_accuracy       1.308170   \n",
       "4           LightGBM_BAG_L2   0.889366  balanced_accuracy       1.287584   \n",
       "5         LightGBMXT_BAG_L2   0.888107  balanced_accuracy       1.283041   \n",
       "6       WeightedEnsemble_L2   0.887503  balanced_accuracy       1.076430   \n",
       "7     NeuralNetTorch_BAG_L2   0.884334  balanced_accuracy       1.323828   \n",
       "8    NeuralNetFastAI_BAG_L2   0.875031  balanced_accuracy       1.403416   \n",
       "9     ExtraTreesGini_BAG_L2   0.874998  balanced_accuracy       1.436731   \n",
       "10  RandomForestEntr_BAG_L2   0.874390  balanced_accuracy       1.464191   \n",
       "11    ExtraTreesEntr_BAG_L2   0.873121  balanced_accuracy       1.400434   \n",
       "12  RandomForestGini_BAG_L2   0.871866  balanced_accuracy       1.406775   \n",
       "13   NeuralNetFastAI_BAG_L1   0.871234  balanced_accuracy       0.184011   \n",
       "14    NeuralNetTorch_BAG_L1   0.870551  balanced_accuracy       0.060479   \n",
       "15          CatBoost_BAG_L1   0.868097  balanced_accuracy       0.012960   \n",
       "16          LightGBM_BAG_L1   0.865012  balanced_accuracy       0.073308   \n",
       "17  RandomForestGini_BAG_L1   0.861300  balanced_accuracy       0.118791   \n",
       "18        LightGBMXT_BAG_L1   0.859436  balanced_accuracy       0.189651   \n",
       "19           XGBoost_BAG_L1   0.858139  balanced_accuracy       0.042822   \n",
       "20     LightGBMLarge_BAG_L1   0.856267  balanced_accuracy       0.076943   \n",
       "21  RandomForestEntr_BAG_L1   0.855663  balanced_accuracy       0.117259   \n",
       "22    ExtraTreesEntr_BAG_L1   0.853191  balanced_accuracy       0.165982   \n",
       "23    ExtraTreesGini_BAG_L1   0.848200  balanced_accuracy       0.152776   \n",
       "24    KNeighborsDist_BAG_L1   0.848102  balanced_accuracy       0.032811   \n",
       "25    KNeighborsUnif_BAG_L1   0.846234  balanced_accuracy       0.035699   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   93.181199                0.002497           1.990012            3   \n",
       "1   88.950525                0.018195          14.548193            2   \n",
       "2   83.322735                0.059767           8.920403            2   \n",
       "3   79.942836                0.044678           5.540503            2   \n",
       "4   80.495197                0.024093           6.092865            2   \n",
       "5   76.642994                0.019549           2.240662            2   \n",
       "6   59.366956                0.006011           1.384510            2   \n",
       "7   85.430761                0.060336          11.028428            2   \n",
       "8   84.852895                0.139925          10.450563            2   \n",
       "9   75.409857                0.173239           1.007524            2   \n",
       "10  75.704287                0.200700           1.301955            2   \n",
       "11  75.288907                0.136942           0.886575            2   \n",
       "12  75.909076                0.143283           1.506744            2   \n",
       "13  14.221804                0.184011          14.221804            1   \n",
       "14  21.749640                0.060479          21.749640            1   \n",
       "15  12.415411                0.012960          12.415411            1   \n",
       "16   3.361433                0.073308           3.361433            1   \n",
       "17   1.040795                0.118791           1.040795            1   \n",
       "18   5.492260                0.189651           5.492260            1   \n",
       "19   5.266464                0.042822           5.266464            1   \n",
       "20   7.791990                0.076943           7.791990            1   \n",
       "21   0.940482                0.117259           0.940482            1   \n",
       "22   0.885833                0.165982           0.885833            1   \n",
       "23   1.221231                0.152776           1.221231            1   \n",
       "24   0.005994                0.032811           0.005994            1   \n",
       "25   0.008995                0.035699           0.008995            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         26  \n",
       "1        True         19  \n",
       "2        True         25  \n",
       "3        True         23  \n",
       "4        True         16  \n",
       "5        True         15  \n",
       "6        True         14  \n",
       "7        True         24  \n",
       "8        True         22  \n",
       "9        True         20  \n",
       "10       True         18  \n",
       "11       True         21  \n",
       "12       True         17  \n",
       "13       True         10  \n",
       "14       True         12  \n",
       "15       True          7  \n",
       "16       True          4  \n",
       "17       True          5  \n",
       "18       True          3  \n",
       "19       True         11  \n",
       "20       True         13  \n",
       "21       True          6  \n",
       "22       True          9  \n",
       "23       True          8  \n",
       "24       True          2  \n",
       "25       True          1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'balanced_accuracy': 0.8722087469680678,\n",
       " 'accuracy': 0.8725,\n",
       " 'mcc': 0.7452659076092105,\n",
       " 'roc_auc': 0.9420869695681529,\n",
       " 'f1': 0.8682170542635659,\n",
       " 'precision': 0.8842105263157894,\n",
       " 'recall': 0.8527918781725888}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(valid_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = predictor.predict_proba(pd.DataFrame(test_x))\n",
    "output_path = path.join(OUTPUT_DIR_AUTOGLUON, UNIQUE_ID, \"manual_model_pred.txt\")\n",
    "np.savetxt(output_path, proba.values[:, 1], delimiter=\"\\n\")\n",
    "# predictor.save(path.join(OUTPUT_DIR_AUTOGLUON, UNIQUE_ID, \"manual_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLJar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: output\\mljar\\20240111_191521\n",
      "The task is binary_classification with evaluation metric f1\n",
      "AutoML will use algorithms: ['Decision Tree', 'Linear', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree f1 0.742515 trained in 6.15 seconds\n",
      "Disable stacking for split validation\n",
      "* Step simple_algorithms will try to check up to 3 models\n",
      "2_DecisionTree f1 0.618182 trained in 5.17 seconds\n",
      "3_DecisionTree f1 0.618182 trained in 5.29 seconds\n",
      "4_Linear f1 0.634146 trained in 6.69 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "5_Default_LightGBM f1 0.84472 trained in 6.16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_Default_Xgboost f1 0.819876 trained in 5.88 seconds\n",
      "7_Default_CatBoost f1 0.860606 trained in 7.91 seconds\n",
      "8_Default_NeuralNetwork f1 0.813953 trained in 6.04 seconds\n",
      "9_Default_RandomForest f1 0.742515 trained in 8.51 seconds\n",
      "10_Default_ExtraTrees f1 0.722892 trained in 6.19 seconds\n",
      "11_Default_NearestNeighbors f1 0.783626 trained in 5.71 seconds\n",
      "* Step not_so_random will try to check up to 61 models\n",
      "21_LightGBM f1 0.795031 trained in 5.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_Xgboost f1 0.825 trained in 9.71 seconds\n",
      "30_CatBoost f1 0.831325 trained in 6.02 seconds\n",
      "39_RandomForest f1 0.773006 trained in 6.47 seconds\n",
      "48_ExtraTrees f1 0.809816 trained in 6.31 seconds\n",
      "57_NeuralNetwork f1 0.737968 trained in 5.19 seconds\n",
      "66_NearestNeighbors f1 0.75 trained in 5.51 seconds\n",
      "22_LightGBM f1 0.829268 trained in 8.45 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_Xgboost f1 0.730539 trained in 8.53 seconds\n",
      "31_CatBoost f1 0.812121 trained in 6.19 seconds\n",
      "40_RandomForest f1 0.701754 trained in 6.56 seconds\n",
      "49_ExtraTrees f1 0.708861 trained in 7.71 seconds\n",
      "58_NeuralNetwork f1 0.745098 trained in 7.16 seconds\n",
      "67_NearestNeighbors f1 0.773006 trained in 7.06 seconds\n",
      "23_LightGBM f1 0.840764 trained in 8.25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14_Xgboost f1 0.807453 trained in 7.96 seconds\n",
      "32_CatBoost f1 0.822086 trained in 8.27 seconds\n",
      "41_RandomForest f1 0.686747 trained in 6.25 seconds\n",
      "50_ExtraTrees f1 0.716763 trained in 7.68 seconds\n",
      "59_NeuralNetwork f1 0.823529 trained in 6.51 seconds\n",
      "68_NearestNeighbors f1 0.773006 trained in 5.6 seconds\n",
      "24_LightGBM f1 0.840764 trained in 7.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15_Xgboost f1 0.745342 trained in 7.93 seconds\n",
      "33_CatBoost f1 0.824242 trained in 7.99 seconds\n",
      "42_RandomForest f1 0.754717 trained in 5.8 seconds\n",
      "51_ExtraTrees f1 0.729412 trained in 6.32 seconds\n",
      "60_NeuralNetwork f1 0.835443 trained in 5.4 seconds\n",
      "69_NearestNeighbors f1 0.773006 trained in 5.12 seconds\n",
      "25_LightGBM f1 0.834356 trained in 5.86 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16_Xgboost f1 0.678363 trained in 6.82 seconds\n",
      "34_CatBoost f1 0.817073 trained in 5.56 seconds\n",
      "43_RandomForest f1 0.733728 trained in 5.66 seconds\n",
      "52_ExtraTrees f1 0.72 trained in 5.54 seconds\n",
      "61_NeuralNetwork f1 0.829268 trained in 5.34 seconds\n",
      "70_NearestNeighbors f1 0.75 trained in 5.14 seconds\n",
      "26_LightGBM f1 0.85 trained in 5.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17_Xgboost f1 0.772152 trained in 5.64 seconds\n",
      "35_CatBoost f1 0.824242 trained in 5.69 seconds\n",
      "44_RandomForest f1 0.792453 trained in 5.92 seconds\n",
      "53_ExtraTrees f1 0.746988 trained in 6.89 seconds\n",
      "62_NeuralNetwork f1 0.8125 trained in 5.62 seconds\n",
      "71_NearestNeighbors f1 0.773006 trained in 5.28 seconds\n",
      "27_LightGBM f1 0.833333 trained in 6.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18_Xgboost f1 0.760736 trained in 6.22 seconds\n",
      "36_CatBoost f1 0.860606 trained in 5.77 seconds\n",
      "45_RandomForest f1 0.792453 trained in 5.97 seconds\n",
      "54_ExtraTrees f1 0.754491 trained in 5.71 seconds\n",
      "63_NeuralNetwork f1 0.820513 trained in 5.37 seconds\n",
      "72_NearestNeighbors f1 0.773006 trained in 5.5 seconds\n",
      "28_LightGBM f1 0.832298 trained in 5.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19_Xgboost f1 0.836364 trained in 6.96 seconds\n",
      "37_CatBoost f1 0.831325 trained in 6.64 seconds\n",
      "46_RandomForest f1 0.721519 trained in 5.82 seconds\n",
      "55_ExtraTrees f1 0.690476 trained in 5.86 seconds\n",
      "64_NeuralNetwork f1 0.825 trained in 6.01 seconds\n",
      "29_LightGBM f1 0.843373 trained in 5.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20_Xgboost f1 0.770186 trained in 6.68 seconds\n",
      "38_CatBoost f1 0.814371 trained in 5.66 seconds\n",
      "47_RandomForest f1 0.77707 trained in 5.86 seconds\n",
      "56_ExtraTrees f1 0.722892 trained in 5.77 seconds\n",
      "65_NeuralNetwork f1 0.8125 trained in 5.44 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: feature_9_multiply_feature_8\n",
      "Add Golden Feature: feature_4_ratio_feature_1\n",
      "Add Golden Feature: feature_1_ratio_feature_4\n",
      "Add Golden Feature: feature_9_sum_feature_5\n",
      "Add Golden Feature: feature_7_multiply_feature_4\n",
      "Add Golden Feature: feature_5_sum_feature_4\n",
      "Add Golden Feature: feature_4_ratio_feature_2\n",
      "Add Golden Feature: feature_2_ratio_feature_4\n",
      "Add Golden Feature: feature_10_multiply_feature_9\n",
      "Add Golden Feature: feature_4_diff_feature_8\n",
      "Created 10 Golden Features in 13.82 seconds.\n",
      "36_CatBoost_GoldenFeatures f1 0.86747 trained in 20.09 seconds\n",
      "7_Default_CatBoost_GoldenFeatures f1 0.826347 trained in 5.67 seconds\n",
      "26_LightGBM_GoldenFeatures f1 0.853659 trained in 6.55 seconds\n",
      "* Step kmeans_features will try to check up to 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36_CatBoost_KMeansFeatures f1 0.802469 trained in 6.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_Default_CatBoost_KMeansFeatures f1 0.807229 trained in 5.79 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26_LightGBM_KMeansFeatures f1 0.817073 trained in 6.07 seconds\n",
      "* Step insert_random_feature will try to check up to 1 model\n",
      "36_CatBoost_GoldenFeatures_RandomFeature f1 0.845238 trained in 6.04 seconds\n",
      "Drop features ['random_feature', 'feature_2_ratio_feature_4']\n",
      "* Step features_selection will try to check up to 6 models\n",
      "36_CatBoost_GoldenFeatures_SelectedFeatures f1 0.860606 trained in 6.22 seconds\n",
      "26_LightGBM_GoldenFeatures_SelectedFeatures f1 0.848101 trained in 6.61 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19_Xgboost_SelectedFeatures f1 0.836364 trained in 7.64 seconds\n",
      "60_NeuralNetwork_SelectedFeatures f1 0.835443 trained in 6.05 seconds\n",
      "48_ExtraTrees_SelectedFeatures f1 0.809816 trained in 6.72 seconds\n",
      "44_RandomForest_SelectedFeatures f1 0.792453 trained in 6.28 seconds\n",
      "* Step hill_climbing_1 will try to check up to 28 models\n",
      "73_CatBoost_GoldenFeatures f1 0.864198 trained in 6.74 seconds\n",
      "74_CatBoost f1 0.8 trained in 5.69 seconds\n",
      "75_CatBoost f1 0.840237 trained in 7.02 seconds\n",
      "76_CatBoost_GoldenFeatures_SelectedFeatures f1 0.872727 trained in 6.72 seconds\n",
      "77_LightGBM_GoldenFeatures f1 0.853659 trained in 6.42 seconds\n",
      "78_LightGBM_GoldenFeatures f1 0.853659 trained in 6.91 seconds\n",
      "79_LightGBM f1 0.85 trained in 7.41 seconds\n",
      "80_LightGBM f1 0.85 trained in 7.29 seconds\n",
      "81_LightGBM_GoldenFeatures_SelectedFeatures f1 0.848101 trained in 7.87 seconds\n",
      "82_LightGBM_GoldenFeatures_SelectedFeatures f1 0.848101 trained in 7.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83_Xgboost_SelectedFeatures f1 0.792453 trained in 7.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84_Xgboost_SelectedFeatures f1 0.834356 trained in 7.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85_Xgboost f1 0.792453 trained in 7.35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86_Xgboost f1 0.834356 trained in 7.83 seconds\n",
      "87_NeuralNetwork f1 0.825581 trained in 6.71 seconds\n",
      "88_NeuralNetwork_SelectedFeatures f1 0.825581 trained in 6.71 seconds\n",
      "89_NeuralNetwork f1 0.768116 trained in 7.02 seconds\n",
      "* Step hill_climbing_2 will try to check up to 21 models\n",
      "90_CatBoost_GoldenFeatures_SelectedFeatures f1 0.814815 trained in 7.44 seconds\n",
      "91_CatBoost_GoldenFeatures f1 0.832298 trained in 7.57 seconds\n",
      "92_LightGBM_GoldenFeatures f1 0.843373 trained in 6.92 seconds\n",
      "93_LightGBM_GoldenFeatures f1 0.8625 trained in 8.44 seconds\n",
      "94_LightGBM_GoldenFeatures f1 0.843373 trained in 7.14 seconds\n",
      "95_LightGBM_GoldenFeatures f1 0.8625 trained in 8.29 seconds\n",
      "96_LightGBM_GoldenFeatures f1 0.843373 trained in 7.27 seconds\n",
      "97_LightGBM_GoldenFeatures f1 0.8625 trained in 8.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AUTOML_HM2\\.venv\\lib\\site-packages\\xgboost\\training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98_Xgboost f1 0.792899 trained in 8.25 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble f1 0.89441 trained in 30.66 seconds\n",
      "AutoML fit time: 943.06 seconds\n",
      "AutoML best model: Ensemble\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoML(eval_metric=&#x27;f1&#x27;, ml_task=&#x27;binary_classification&#x27;, mode=&#x27;Compete&#x27;,\n",
       "       random_state=42, results_path=&#x27;output\\\\mljar\\\\20240111_191521&#x27;,\n",
       "       total_time_limit=900)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML(eval_metric=&#x27;f1&#x27;, ml_task=&#x27;binary_classification&#x27;, mode=&#x27;Compete&#x27;,\n",
       "       random_state=42, results_path=&#x27;output\\\\mljar\\\\20240111_191521&#x27;,\n",
       "       total_time_limit=900)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AutoML(eval_metric='f1', ml_task='binary_classification', mode='Compete',\n",
       "       random_state=42, results_path='output\\\\mljar\\\\20240111_191521',\n",
       "       total_time_limit=900)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl = AutoML(\n",
    "    mode=\"Compete\",\n",
    "    ml_task=\"binary_classification\",\n",
    "    total_time_limit=TRAIN_TIME_LIMIT_MLJAR,\n",
    "    eval_metric=\"f1\",\n",
    "    random_state=SEED,\n",
    "    results_path=path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID),\n",
    ")\n",
    "\n",
    "automl.fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10) (400, 1)\n",
      "(1600, 10) (1600, 1)\n",
      "Model Balanced Accuracy: 0.8721337300892701\n"
     ]
    }
   ],
   "source": [
    "print (valid_x.shape, valid_y.shape)\n",
    "print(train_x.shape, train_y.shape)\n",
    "predictions = automl.predict(valid_x)\n",
    "score = balanced_accuracy_score(valid_y, predictions)\n",
    "print(f\"Model Balanced Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = automl.predict_proba(test_x)\n",
    "output_path = path.join(OUTPUT_DIR_MLJAR, UNIQUE_ID, \"mljar_model_proba.txt\")\n",
    "np.savetxt(output_path, proba[:, 1], delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(X, model1, model2):\n",
    "    # Get predictions from each model\n",
    "    pred1 = model1.predict_proba(pd.DataFrame(X)).values[:, 1]\n",
    "    pred2 = model2.predict_proba(X)[:, 1]\n",
    "    # pred3 = model3.predict_proba(X)[:,1]\n",
    "    print(pred1, pred2)\n",
    "    # Average the probabilities for the positive class\n",
    "    avg_pred = (pred1 + pred2) / 2\n",
    "\n",
    "    # Convert to binary predictions (you might adjust the threshold as needed)\n",
    "    # final_pred = [1 if p >= 0.5 else 0 for p in avg_pred]\n",
    "    return avg_pred\n",
    "\n",
    "\n",
    "# Example of using the ensemble\n",
    "final_predictions = ensemble_predict(test_x, predictor, automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_predictions)\n",
    "os.makedirs(path.join(\"ensamble\", UNIQUE_ID), exist_ok=True)\n",
    "np.savetxt(\n",
    "    path.join(\"ensamble\", UNIQUE_ID, \"123manual_model_pred.txt\"), final_predictions, delimiter=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install auto-sklearn\n",
    "# !pip install ydata-profiling\n",
    "# from autosklearn.classification import AutoSklearnClassifier\n",
    "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
    "from autosklearn.metrics import balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"time_left_for_this_task\": TRAIN_TIME_LIMIT_AUTO_SKLEARN,\n",
    "    \"seed\": SEED,\n",
    "    \"metric\": balanced_accuracy,\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "askl2 = AutoSklearn2Classifier(**settings)\n",
    "askl2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard = askl2.leaderboard(sort_by=\"model_id\", ensemble_only=True)\n",
    "print(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = askl2.predict(valid_x)\n",
    "balanced_accuracy_score(valid_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = askl2.predict_proba(test_x)\n",
    "output_path = path.join(OUTPUT_DIR_AUTO_SKLEARN, UNIQUE_ID, \"manual_model.txt\")\n",
    "np.savetxt(output_path, proba, delimiter=\"\\n\")\n",
    "askl2.save(path.join(OUTPUT_DIR_AUTO_SKLEARN, UNIQUE_ID, \"manual_model.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
